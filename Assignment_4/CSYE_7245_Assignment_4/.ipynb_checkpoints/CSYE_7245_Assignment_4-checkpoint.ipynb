{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import time\n",
    "%matplotlib inline\n",
    "# !pip install keras\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import itertools\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# convert to one-hot-encoding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A - Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv(\"training_BigDataAssignment4.csv\")\n",
    "test = pd.read_csv(\"testing_BigDataAssignment4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEFCAYAAAD5bXAgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ef7faa6358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = train[\"label\"]\n",
    "\n",
    "# drop 'label' column\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "\n",
    "# free some space\n",
    "del train \n",
    "\n",
    "g = sns.countplot(Y_train)\n",
    "\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Checking for Null and Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data\n",
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28000.000000</td>\n",
       "      <td>28000.000000</td>\n",
       "      <td>28000.000000</td>\n",
       "      <td>28000.000000</td>\n",
       "      <td>28000.000000</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164607</td>\n",
       "      <td>0.073214</td>\n",
       "      <td>0.028036</td>\n",
       "      <td>0.011250</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.473293</td>\n",
       "      <td>3.616811</td>\n",
       "      <td>1.813602</td>\n",
       "      <td>1.205211</td>\n",
       "      <td>0.807475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pixel0   pixel1   pixel2   pixel3   pixel4   pixel5   pixel6   pixel7  \\\n",
       "count  28000.0  28000.0  28000.0  28000.0  28000.0  28000.0  28000.0  28000.0   \n",
       "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel8   pixel9    ...         pixel774      pixel775      pixel776  \\\n",
       "count  28000.0  28000.0    ...     28000.000000  28000.000000  28000.000000   \n",
       "mean       0.0      0.0    ...         0.164607      0.073214      0.028036   \n",
       "std        0.0      0.0    ...         5.473293      3.616811      1.813602   \n",
       "min        0.0      0.0    ...         0.000000      0.000000      0.000000   \n",
       "25%        0.0      0.0    ...         0.000000      0.000000      0.000000   \n",
       "50%        0.0      0.0    ...         0.000000      0.000000      0.000000   \n",
       "75%        0.0      0.0    ...         0.000000      0.000000      0.000000   \n",
       "max        0.0      0.0    ...       253.000000    254.000000    193.000000   \n",
       "\n",
       "           pixel777      pixel778  pixel779  pixel780  pixel781  pixel782  \\\n",
       "count  28000.000000  28000.000000   28000.0   28000.0   28000.0   28000.0   \n",
       "mean       0.011250      0.006536       0.0       0.0       0.0       0.0   \n",
       "std        1.205211      0.807475       0.0       0.0       0.0       0.0   \n",
       "min        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
       "25%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
       "50%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
       "75%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
       "max      187.000000    119.000000       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       pixel783  \n",
       "count   28000.0  \n",
       "mean        0.0  \n",
       "std         0.0  \n",
       "min         0.0  \n",
       "25%         0.0  \n",
       "50%         0.0  \n",
       "75%         0.0  \n",
       "max         0.0  \n",
       "\n",
       "[8 rows x 784 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Checked for corrupted images (that is, missing values inside)\n",
    "* There is no missing values in the training and testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Performing a grayscale normalization (as images are a single channel image / grayscale) to reduce the effect of illumination's differences\n",
    "* Also, the CNN converg faster on [0..1] data than on [0..255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are 10 digits from 0 to 9. Encoded these lables to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training & Valdiation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the training and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPkAAAD3CAYAAADfRfLgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ef005ab780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# An example\n",
    "g = plt.imshow(X_train[5][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B - Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model \n",
    "The Keras Sequential API is used, where you have just to add one layer at a time, starting from the input.\n",
    "\n",
    "The first is the convolutional (Conv2D) layer. It is like a set of learnable filters.Set 32 filters for the two firsts conv2D layers and 64 filters for the two last ones. Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. The kernel filter matrix is applied on the whole image. Filters can be seen as a transformation of the image.\n",
    "\n",
    "The CNN can isolate features that are useful everywhere from these transformed images (feature maps).\n",
    "\n",
    "The second important layer in CNN is the pooling (MaxPool2D) layer. This layer simply acts as a downsampling filter. It looks at the 2 neighboring pixels and picks the maximal value. These are used to reduce computational cost, and to some extent also reduce overfitting. We have to choose the pooling size (i.e the area size pooled each time) more the pooling dimension is high, more the downsampling is important.\n",
    "\n",
    "Combining convolutional and pooling layers, CNN are able to combine local features and learn more global features of the image.\n",
    "\n",
    "Dropout is a regularization method, where a proportion of nodes in the layer are randomly ignored (setting their wieghts to zero) for each training sample. This drops randomly a propotion of the network and forces the network to learn features in a distributed way. This technique also improves generalization and reduces the overfitting.\n",
    "\n",
    "**'relu' is the rectifier (activation function max(0,x)). The rectifier activation function is used to add non linearity to the network.**\n",
    "\n",
    "The Flatten layer is use to convert the final feature maps into a one single 1D vector. This flattening step is needed so that you can make use of fully connected layers after some convolutional/maxpool layers. It combines all the found local features of the previous convolutional layers.\n",
    "\n",
    "In the end we used the features in two fully-connected (Dense) layers which is just artificial neural networks (ANN) classifier. In the last layer (Dense(10,activation=\"softmax\")) the net outputs distribution of probability of each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rectified Linear Unit (ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Relu  13.172165193457149\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "# Set the CNN model \n",
    "# my CNN architechture is:\n",
    "# In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "  \n",
    "print (\"Using Relu \",time.clock() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TanH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tanh :  0.2915879644108639\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "# Set the CNN model \n",
    "# my CNN architechture is:\n",
    "# In -> [[Conv2D->tanh]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='tanh', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='tanh'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='tanh'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='tanh'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"tanh\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "  \n",
    "print (\"Using tanh : \",time.clock() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Exponential Linear Unit (SELU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using selu : 6.911236228794126\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "# Set the CNN model \n",
    "# my CNN architechture is:\n",
    "# In -> [[Conv2D->selu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='selu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='selu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='selu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='selu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"selu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "  \n",
    "print (\"Using selu :\",time.clock() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Linear Unit (ELU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using elu : 0.4311596506281177\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "# Set the CNN model \n",
    "# my CNN architechture is:\n",
    "# In -> [[Conv2D->elu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='elu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='elu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='elu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='elu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"elu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "  \n",
    "print (\"Using elu :\",time.clock() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the optimizer and annealer.\n",
    "Once our layers are added to the model, we need to set up a score function, a loss function and an optimisation algorithm.\n",
    "\n",
    "We define the loss function to measure how poorly our model performs on images with known labels. It is the error rate between the oberved labels and the predicted ones. We use a specific form for categorical classifications (>2 classes) called the \"categorical_crossentropy\".\n",
    "\n",
    "The most important function is the optimizer. This function will iteratively improve parameters (filters kernel values, weights and bias of neurons ...) in order to minimise the loss.\n",
    "\n",
    "RMSprop (with default values), it is a very effective optimizer. The RMSProp update adjusts the Adagrad method in a very simple way in an attempt to reduce its aggressive, monotonically decreasing learning rate. We could also have used Stochastic Gradient Descent ('sgd') optimizer, but it is slower than RMSprop.\n",
    "\n",
    "The metric function \"accuracy\" is used is to evaluate the performance our model. This metric function is similar to the loss function, except that the results from the metric evaluation are not used when training the model (only for evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C - Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer , loss = \"mean_absolute_error\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer , loss = \"mean_squared_error\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer , loss = \"hinge\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 1 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 368s - loss: 0.9285 - acc: 0.7179 - val_loss: 0.9129 - val_acc: 0.8719\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categorical_crossentropy\n",
    "Epoch 1/2\n",
    " - 267s - loss: 0.2255 - acc: 0.9561 - val_loss: 0.0704 - val_acc: 0.9876\n",
    "Epoch 2/2\n",
    " - 211s - loss: 0.1852 - acc: 0.9610 - val_loss: 0.0508 - val_acc: 0.9871"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_absolute_error\n",
    "Epoch 1/2\n",
    " - 206s - loss: 0.0136 - acc: 0.9323 - val_loss: 0.0052 - val_acc: 0.9748\n",
    "Epoch 2/2\n",
    " - 210s - loss: 0.0128 - acc: 0.9366 - val_loss: 0.0047 - val_acc: 0.9767"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared error :\n",
    "Epoch 1/2\n",
    " - 229s - loss: 0.0240 - acc: 0.8346 - val_loss: 0.0062 - val_acc: 0.9629\n",
    "Epoch 2/2\n",
    " - 229s - loss: 0.0134 - acc: 0.9215 - val_loss: 0.0056 - val_acc: 0.9683"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hinge\n",
    "Epoch 1/2\n",
    " - 204s - loss: 0.9041 - acc: 0.9594 - val_loss: 0.9015 - val_acc: 0.9857\n",
    "Epoch 2/2\n",
    " - 206s - loss: 0.9037 - acc: 0.9636 - val_loss: 0.9018 - val_acc: 0.9824\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D - Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is change of accuracy when we chane the epoch frequency:\n",
    "Epoch 3/10\n",
    " - 268s - loss: 0.0664 - acc: 0.9810 - val_loss: 0.0352 - val_acc: 0.9907\n",
    "Epoch 4/10\n",
    " - 266s - loss: 0.0641 - acc: 0.9819 - val_loss: 0.0204 - val_acc: 0.9938\n",
    "Epoch 5/10\n",
    " - 270s - loss: 0.0611 - acc: 0.9829 - val_loss: 0.0329 - val_acc: 0.9898\n",
    "Epoch 6/10\n",
    " - 283s - loss: 0.0621 - acc: 0.9825 - val_loss: 0.0255 - val_acc: 0.9924\n",
    "Epoch 7/10\n",
    " - 294s - loss: 0.0631 - acc: 0.9825 - val_loss: 0.0191 - val_acc: 0.9940\n",
    "Epoch 8/10\n",
    " - 288s - loss: 0.0595 - acc: 0.9843 - val_loss: 0.0254 - val_acc: 0.9933\n",
    "Epoch 9/10\n",
    " - 229s - loss: 0.0600 - acc: 0.9838 - val_loss: 0.0234 - val_acc: 0.9938\n",
    "Epoch 10/10\n",
    " - 222s - loss: 0.0631 - acc: 0.9831 - val_loss: 0.0243 - val_acc: 0.9914"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model Training and Validation Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD3CAYAAADxJYRbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ef00581a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAEiCAYAAABqcBCCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsnXdYFMcbxz93RxFFRGyAWMCSYoko\nKir2gh272BVLijV2ETGJicaYEFss0SQqYktsGE1RY0JsiAYN9i4KiAULRSl39/uDn6dG4DhuF+5k\nPj77PN7e3nffm13em5mdma9Cq9VqEQgEAsFLKAs6AIFAIDBFRHIUCASCLBDJUSAQCLJAJEeBQCDI\nApEcBQKBIAtEchQIBIIsEMnRDFCr1fzwww/06NEDHx8fOnbsyIIFC0hLSzNK8/3338fb25v169cb\n/PmoqCjGjRuX5/NLTWJiIoMHD872fR8fHx4/fpyPEQnMHYUY52j6zJo1i0ePHvHZZ59RvHhxUlJS\nmDx5MsWKFWPBggV50oyNjcXb25uTJ0+iUqkkjjj/uXXrFl26dCEyMrKgQxG8Joiao4lz69Ytdu3a\nxdy5cylevDgARYsW5eOPP6ZNmzZAZq1p8uTJdO7cmS5duvDFF1+QkZEBQK1atViyZAm+vr60atWK\nDRs2kJSUxIgRI8jIyKBHjx5ER0fzxhtvkJCQoDvvs9fJycmMGzcOHx8funfvTkBAABqNhvDwcDp3\n7pyn82dFrVq1CAoKolevXnTs2JE9e/Ywbtw42rdvz+DBg0lJSQHgp59+onfv3nTr1o2WLVvq9GbM\nmMHTp0/x8fFBrVZTs2ZNxo8fj7e3N1FRUbrvs3TpUnx9fVGr1dy9excvLy+OHj0qw5UTmD1agUnz\n66+/anv27JnjMVOnTtXOmTNHq9FotKmpqVo/Pz/typUrtVqtVlu9enVtcHCwVqvVaqOiorQ1a9bU\nPn36VHvz5k1tnTp1dBrVq1fX3r9//5XX27dv1/r5+Wm1Wq02IyNDO3PmTO3169e1R48e1Xbq1CnP\n5/8v1atX165du1ar1Wq1K1eu1Lq7u2tv376tVavV2u7du2tDQ0O1SUlJ2j59+mgTEhK0Wq1WGxkZ\nqfsOWX2f7du3v/J9MjIytAMGDNCuXLlSO3ToUO3y5cv1XgNB4UTUHE0cpVKJRqPJ8ZiwsDAGDhyI\nQqHAysoKX19fwsLCdO+3bt0agBo1apCWlqarheWGevXqcfnyZQYNGsS3337LkCFDqFSpkizn9/b2\nBqBixYpUr16dcuXKoVQqcXFx4dGjRxQrVowVK1bw119/sXDhQlasWJHjd/Hw8Hhln0ql4ssvv2TV\nqlVotVrefffdXJeFoHAhkqOJU7t2ba5evUpSUtJL++Pj4xk1ahRPnz5Fo9GgUCh072k0Gl2zFsDa\n2hpAd4xWTzfziw96KlSowN69exk1ahRJSUkMGzaMP/7446XjpTq/paVllv9/xu3bt+nWrRsxMTHU\nq1ePCRMm5Pg9ihYtmuX+mJgYrK2tiY6O5tGjRzlqCAovIjmaOOXKlaNLly74+/vrEmRSUhIfffQR\n9vb2FClSBC8vL9avX49WqyUtLY0tW7bQuHFjg87j4OBAVFQUAD///LNu/4YNG5gxYwZeXl5MmTIF\nLy8vzp49+9JnpTh/bjh9+jQODg588MEHeHl5ceDAASDzybuFhQVqtVpv4n/8+DFTpkzh888/p3Pn\nzsycOVPyOAWvByI5mgGzZ8+matWq+Pr64uPjQ+/evalatSqffvopAAEBASQkJNClSxe6dOmCq6sr\n7733nkHnCAgI4JNPPqF79+5cuXKFMmXKANCtWzfUajUdO3akR48eJCYmMmjQoFc+a+z5c0OTJk0o\nV64c7du3p0OHDsTFxeHg4MCNGzcoU6YMtWvXplOnTjx48CDH79miRQu8vLwYM2YMN2/eJCQkRPJY\nBeaPGMojEAgEWSBqjgKBQJAFIjkKBAJBFojkKBAIBFkgkqNAIBBkgUVBBwDw9OlTTp8+TZkyZV6L\neb4CwevCs2mWNWvWpEiRIpJoPnz48JVxu9lha2uLvb29JOc1FJNIjqdPn2bAgAEFHYZAIMiGkJCQ\nLGccGcrDhw/xaNgEFRn6DwZKlCjB77//XiAJ0iSS47MxdfFu/VFb2kmuf3JJb8k1BQWHnKPPXpzp\nIzXmGHf87dsMGzxA9zdqLElJSajIIL5IAzIUOddELbRP4dExkpKSCm9yfNaUVlvaobYqIbl++fIu\nkmsKCg5zTDJgvnEDknd3ZSiLoFZmPb1TR85LCsiOSSRHgUBQyFAoMzd9xxQgJvu0ukv9isQHP5+m\nNrl7bSIX9SBqSS9m9nHX7a9RsSR3ggdxdIGPbqvmnLem+S97dlPfvTa1a7xBf9/ekq4crdVqGTFs\nCF8HfSmZ5jPkjBvki13OuDeGrKdhvTo09HCnZbMmnDhxXDJtEbcEKBS52woQk0yOVRztmDu4Ac+K\nxtvdhZ6NXWkyNRSPidtpVsORHo1cAfB8oyxbDl7Fc8pO3XYp1vCLfvfuXd4dMYyNW7by75kLuLq6\nMct/uiTf5/y5c3Ro15rt236SRO9F5Iwb5ItdzrgvXriA/4yp7Pj5F8KPRzJtxkz69ekpibaIWyKe\n1Rz1bQWIySVHGysV349vzvS14bp9XRtWYvPfV0hJzSA1XU3wgUv0a1YFgIZvlOUNlxIc/qIrYfO6\n4NOwUnbSObJv7+/U86hP1WrVABj17vts2hgiST/RiuXfMNRvBD16Sv9gSM64Qb7Y5Yzb2tqaZStW\n4eTkBEDdeh7E375tlOfOM0TcUpGbWmPB1hxNrs9xybtN+G7veaJuPF9ZxaVUMQ5Exepex9xPoXyp\nzM7clKcZ/HjwKqv3XqCakx2/fdKRm/eS+OfKfYPOe+vWTVxcKuhel3dx4fHjxyQmJmJnZ9wT9IWL\nlwKwf+/vRulkhZxxg3yxyxl3pcqVqVS5MpDZJTB9yiQ6de6KlZWVUbog4pYMpRKUeh7yFPBa3LIl\nR41Gw0cffcSFCxewsrLi008/fWUF6f8yokNt1GoN6/64RMUytrr9CqWCF3/gFApQazJ3TFh9RLf/\nQswjth66Rsd6FQ1Ojtr/LNj6DFMflC7izp7k5GRGDR/GrVs32fnzL5JoirglojA/kNm3bx9paWls\n3ryZSZMm8fnnn+v9zIDWNahbtQxHF/iw3b8tNlYqji7wIfZ+Mk4Ozx/7O5UsSsz9FJRKBVN7vINt\nkec5XqGAdLXhYwAqVKhIXNwLtdOYGEqWLEmxYsUM1spPRNxZczM6mlbNmqBSqfh17x+SjZMTcUtE\nYX4gc+LECZo2bQpAnTp1OH36tN7PtJy8kfoTt+M5ZSfd5+7lSZoazyk7CQ2/gW/TKhS1tsDKQsnA\nltXYdewGGo2WTvUr4tf2TQAqlC5GN8/K7Dh63eB4W7dtx7Hwo1y+dAmA1d+uoHMXH4N18hsR96sk\nJibi3bYlXbt1Z13IRmxsbCTRBRG3ZJjBAxnZmtVJSUnY2j5vGqtUKjIyMrCwMPyUe07cpEalkoR9\n3gUrCyU/R0QT8tdlAIYt+pPFo5owsEVVVEoFU34I50KM4b4gZcuWZeXqH+jftxdp6Wm4uVVh9Q/r\nDNbJb0Tcr7Ji2VKib9wgdOcOQnfu0O3f89s+SpUqZZS2iFsiclMzLOCao2wrgc+bN4933nmHjh07\nAtCsWbOXHOle5NatW7Ru3ZrYN96TZYZMwiY/yTUFBYe5zjQxx7hjYm7RsV1r9u/fj4uL8TPNnv2t\nx5Tuglplm+OxKnUS5e/tkuzchiJbvbVu3bq6ZHjy5EmqV68u16kEAoHZkZsm9WvarG7bti2HDh3C\n19cXrVbL3Llz5TqVQCAwN5SKzE3fMQWIbMlRqVTyySefyCUvEAjMGTMYymNyg8AFAkEhIDeDwJUi\nOQoEgsKGGTytFslRIBDkP6JZLRAIBFmRmxkwouYoEAgKG6LmKBAIBFmgIBd9jvkSSbaYVHI8uaS3\nLH4vJeuPkVzzGffDl8imLedKe6oCHkNmDHL7pciFnEsnml2RiJqjQCAQZIF4Wi0QCARZIGqOAoFA\nkAViELhAIBBkRW7Wa3xNVwKXCynsJbu0qM2dg89tRru1rsOhkKkc/9GfbYvfw6FE5urIFZ0c2Ln0\nAyK3BnBw/RR6tnXPTjJX7Nq5g3KlpPXr2LB+HY3qu+u2GtXdsC9mRXx8vCT6ctp5mqs2yGu1C/Lc\nK8Ka1TDMKjlKYS9ZpWIZ5n3YXffEs+7bFQma1pt+k1fj0Xsul2/c4aMxXQBYPWcQx6Ku497zU9qP\nWsyHQ9tSq3r5PMV++dIl/KdPkXxNv/4DB3MkIpIjEZGEHT5GOUdHvlq4hHLlyhmtLaedp7lqg7xW\nuyDPvSKsWQ3HrJKjsfaSNkUs+eHTIUwL2qbb169jfdbuOEJ0XAIAn67cQ9CavQC4v1WR4NCjACSl\npBIWcZGuLd8xOO6UlBSGDxvE5198ZfBnDSHoy/mUKVOW4SPflURPTjtPc9UGea125bpXTM6aVdQc\npSUne8ncsHRmP1ZvPUjUxRjdvqqVymJhoWTL16MI3zydhdP7kJSSCkBE1HUG+3gCULqkLd5eNXAs\nbXhTZ+zo9/AbMYqatWob/Nnccu/ePZYsDOLzBUGSaRpb3q+jNmTa1fr26y+J1n+R616Ru0wMRaFQ\n5GorSGRNjqdOnWLQoEGS6RljLzmqd1My1BrW7Tz60n5LCxUdm9Vi7Kcb8fSdT/z9RJbN6gfAyMBg\n3nR1JGKLP8tnD+CXsNOkZ6gNivnbFcuwsLBgyFB5rRp++O5bOnXxwdXNTTJNOe08zVVbTuS8V0yt\nTDIrhvqSY+717t+/T/Pmzbly5Qo3btygX79+9O/fn9mzZ6PRZLqRLl26lF69euHr68u///6rV1O2\np9WrVq0iNDRUUge1ChUqEnEsXPfaEHvJQV0bYlPEiqObpmNlqcLG2pKjm6Zz70ESew+fJf5+5i/o\nup1H+OXbcQAUKWLJqNnrSXmaBsDSgH6cuxJnUMzrg9eSkpKCZ3130tPSePLkCZ713dm+czdOzs4G\naeXE1h+3sCBokWR6YFx5v67aciLnvWJyZaJA//TAXCbH9PR0AgMDKVKkCJDpXzVhwgQaNmxIYGAg\n+/fvx9nZmWPHjvHjjz8SFxfH2LFj2bp1a466stUcK1asyJIl0k6tM8ZesumgL/HoPRdP38/pNmY5\nT1LT8fT9nGUb/6RD05q6J9Q+retw4kw0ALPe68So3pn2slUrlqVT81rs/OOkQTGHHQrneGQURyMi\n2bZzNzY2NhyNiJQ0MT548ICrVy7j2aixZJogr52nuWrLiZz3iqmViZTN6vnz5+Pr60vZsmUBOHPm\nDA0aNAAyjf0OHz7MiRMn8PLyQqFQ4OzsjFqtJiEhIUdd2WqO3t7e3Lp1S1JNOewl94Sdpnw5e35f\nPR6lUkF0XALvf7wBAP+vt/Pdp4MZ0KUhGWo1IwODuRX/UIqvIilXr1zG0dEJS0tLSXXltPM0V21z\nxdTKRKlQotUzyFuZi6fV27Ztw8HBgaZNm/Ltt98CmcOsniXWYsWKkZiYSFJSEvb29rrPPdvv4OCQ\nrbZs1qyQacM4ceJEtmzZove41q1bs+f3/WLhiRcQC0+8Xmg08l1RpUzXUy5r1rs1xqC2ts/xWFXq\nQ8qcWZrjuQcMGKCrZZ47d47KlStz9uxZzp49C8C+ffs4fPgwlStXJjU1lZEjRwLQrVs3vv/++xyT\no1k9rRYIBK8JilxueggJCWH9+vUEBwfz1ltvMX/+fJo1a0Z4eGb/alhYGB4eHtStW5eDBw+i0WiI\njY1Fo9HkmBhBTB8UCAQFQW76FPM4lGfatGnMmjWLoKAg3Nzc8Pb2RqVS4eHhQd++fdFoNAQGBurV\nkTU5uri46G1SCwSCwkduHrgYOs4xODhY9//169e/8v7YsWMZO3ZsrvVEzVEgEOQ7ciRHqRHJUSAQ\n5DvPBoHrO6YgEclRIBAUDCY+YEIkR4FAkO+IZrVAIBBkgVKp1LvSt1KsBC4QCAodEs6tlotCkRwf\nRCyVTdtpWIhs2rHfy7MsliB75JzFIniOaFYLBAJBVsg4CFwqRHIUCAT5jiIXK32LmqNAICh0KMhF\ncizgTkeRHAUCQf5jBg9kzG5VHlO28xzZpjqH53Xi8LxOhExoRmk7a5QKBV8Nrc+Rzztz5PPOfNLv\nub2r11vl+HNOBw5+1pHQGa2pWTHnJZyyY/mypdR7pyYedWrRu0c37ty5kyedrDDl8taHOdqnTp86\niTeqVsKzvjue9d0ZPMBXUn25yyS3SG2TIAdmlRxN2c7zncoOjOn4Fu0/+Z3GM3ZzJT6RmT3foa+X\nK1Wd7GgyYzdNZ+6myZvl8GlQETsbS4LHNyVw4z94zdzDpDURfD+mKVYWhl2Sf/45waKvv+KPsEMc\nPxlF1WpV+eSjWYZ+/Swx5fLWhznapwKEHz3C2uCNHI2I5GhEJOtCNkmmLXeZGEKhN9iSGlO28zx1\nPYF6U0J5/CQda0slziWLkpCUikqpoKi1BdaWSqwtVFhZKElNV+PmWJzHKemEnY0H4FLcYxKfpFO/\nammD4q5btx5RZy9SokQJnj59SmxMLA4OpQz78tlgyuWtD3O0T01NTeXUyUi+/moB9evWpn/fXtyM\njpZMX84yMRSFUpGrrSAxq+Ro6naeGWotHeu5cGZRdxq9UZaQsKtsCLvKw+Q0zi7uzrklPbgan8iv\nkTFciXtMUWsLWtZ0BMDd1YE3y5fA0d5wQzJLS0tCd+6gmmsFDh4MY/CQYQZrZIWpl3dOmKN9alxs\nLM1btCLw4zkcO3GK+g0a0qdXN8l+MOQsE0MptDXH9PR0pkyZQv/+/enVqxf79++XRNcc7Dz3nLhF\n1Q+2Mn/7v2yd2pJp3Wtx/3Eq1Udvo+b47ZQsZsXoDm+S+DSDgQvDmNi1Jn9/1hFfLzf+PhtPWoYm\nT/F39enGzbi7zJw1m66d2+vsKI3BHMo7v5HTPrWyqyvbQ3dTo0ZNFAoFEyZO5trVK9y4fl3ycxU0\nhTY5hoaGYm9vz4YNG1i1ahVz5syRRLdChYrExcXqXktt52mMtmtZWzyrl9G9Xv/XVSqULoZPg4qs\nD7tCulrD4yfpbDx4jaZvOaJQQHJqOl3m7qPpzD1MCz5OFcfiXLtjWM3pyuXLHD50UPd6yFA/om/c\n4MGDBwbpZIUpl3dBsT54LSeOR+BZ350ePp109qlxsbH6P6yHqKh/2RAS/NI+rVYruXGaaZCbxPga\nJsf27dszfvx43WupagOmbOfpaG/D6tFeONhaA9C7cWXO3XpE5LX7dG9YEQALlYIO7uWJuHIPrRY2\nT2pJHddMH4vuDSuRmq7mdLRh7oa3b8cxeGA/7t27B8CmDSHUqFGTUqWM73c05fIuKOS0T1UqlUyZ\nOJ7r164BsGrlcmrWqk15CYytTA1zqDnKMs7x2a9/UlIS48aNY8KECZLomrKd55GLdwkKPc3PM9uQ\nodZw++ETBiz8i8Qn6SwYXJ/w+Z1Ra7SEnb3N4p8zndFGLj/EIr+GWFooiX/4hAELwwyOu4lXU6ZO\n96d9m5aoLCxwcnZm80/bDdbJClMu79eRGjVq8uXXi+nVoysatRrn8i6sWbehoMOSBzMY5yibNWtc\nXByjR4/W9TvmhNzWrHJirgtPFPSvsqlirgtPmJs1a3rLWVA0Z/c/UhKwPDBHsnMbiiw1x3v37uHn\n50dgYCCNGjWS4xQCgcCMyexS1LfwRL6Eki2y9DmuWLGCx48fs2zZMgYNGsSgQYN4+vSpHKcSCARm\nyLN1J/RtBYksNceAgAACAgLkkBYIBK8BuVmVp6Czo1h4QiAQ5DtKhQL09ZOK5CgQCAoduag4al/H\nZrVAIBDkhDIXc6e1SgXGz/PKOyI5CgSCfCdXD1xEzVEgEBQ2cjUDRvQ5CgSCwoaoORYC5JzFUmbA\nWtm0720YKpu2OSNnZUUt4+wbhUzSMk2gEzVHgUAgyBr9yVErDLYEAkFhwwzGgIvkKBAI8h+lUqF/\nsYwCtkkQyVEgEOQ7z9wH9R1TkJiVhwyYr1WoVPapnetXJG7tAN3rSd1q8c/X3Tm1uAf+vevo9teo\nWJK9n3TgyBddOTS/C23rlM/T+cy1vOXU3hiynob16tDQw52WzZpw4sRxybRDd27H06MOjRvUpZN3\nG65euSKZtpxxG4o5LDxhVsnRXK1CpbJPreJYnM8Geehumnbu5enRqDJe03fRYNJOmtVwpEejygB8\nN7Ypi3adodHUUEYu/Zt1H7bAUmXY5TbX8pZT++KFC/jPmMqOn38h/Hgk02bMpF+fnpJoP3nyhJHD\nBhOy+ScOH/uHDp06M2XSeP0fzAVyxp0XzGElcLNKjuZqFSqFfaqNlYrVY5sxY22Ebl+XBpXYcvAq\nKakZpKarCT5wmb5N3QBoMm0XP0dk2nq6livOo+Q0g4eSmGt5y6ltbW3NshWrcHJyAqBuPQ/ib98m\nLS3NaG21Wo1Wq+Xxo0cAJCclUaRIEaN1Qd6484I51BzNqs8xJztPOzs7k9WG5/apo98biZW1NbNm\nf2zQ5xePasz3+y5wOvq5cZZLqWL8FRWnex2TkEx5h0yLimeJ8N/FPahU1papPxxDY2ByMNfyllO7\nUuXKVKpcGcgcAzh9yiQ6de6KlZWVUboAtra2LFyyjDYtvHAoVQq1Ws3eA38brQvyxp03clMzfE1r\njmq1mhkzZuDr68uAAQOIlsCc3NytQvNqnzqy3RtkqDUEH7j80n6l4uVBugpeHWhce9w2ao/dxsRu\ntWhew9GgeM21vPPjWiYnJzOwX1+uXLnMspWrJNE8czqK+XM/JSLyNJeu3WLKNH8G+vaWdCC2HHHn\nBXOoOcqWHA8cOADApk2bGDduHPPmzTNa01ytQo21Tx3Qoir1qpTm8Bdd2TajDTZWKg5/0ZWYhBQc\nHYrqjnNyKEpsQjKWKiW9Grvqbq4bd5M4EBVHbVfDmvLmWt5y277ejI6mVbMmqFQqft37B/b29pLo\n7tv7Ow0bNcatShUARr33AWfPnOb+/fuS6MsVd14o1H2Obdq00flVx8bGUrp0aaM1zdUq1Fj71Bb+\nu2kweSeNp4bSY94+nqSpaTw1lF3HbtDXy42i1hZYWSgZ2LwquyKiSVdrmOXrTq/GrgA4lrShWQ1H\nDp69bVDc5lrecmonJibi3bYlXbt1Z13IRmxsbCTRBahTx51Df4dxJz4egJ9Dd1C5sqskfztyxp0X\nzKHmKGufo4WFBdOmTWPv3r0sXrzYaD1ztQqVyz71lxO3qFGxJH/N7YSlhYrdx6PZ8Ffm0I/+C/4g\naLgnH/rUQqPRErD+OJFXDauBmGt5y6m9YtlSom/cIHTnDkJ37tDt3/PbPqO9wpu3bMX4iZPp0K4V\nVlZWlCzpwCaJbHbljDsv5GYQuDYXg8DVajUBAQFcu3YNlUrFvHnzMvtUp09HoVBQrVo1Zs+ejVKp\nZOnSpfz5559YWFjg7+9P7dq1c9SWzZr1Re7evUufPn3YvXs3RYsWfeV9c7ZmlbP4xMIT+Y+c11PO\nhSdUMlqzdvJuI7k1a6l+81EVz7lGrE68x/2N03I89759+9i/fz/z5s0jPDycNWvWoNVqGTZsGA0b\nNiQwMJCmTZvi7OzM/PnzWbt2LXFxcYwdO5atW7fmeH7Zao47duwgPj6ed999FxsbGxQKhaQd4gKB\nwHzJTZ9ibvoc27RpQ4sWLYDn3Xd//vknDRo0AKBZs2YcOnQIV1dXvLy8UCgUODs7o1arSUhIwMEh\ne+9s2foc27Vrx9mzZxkwYADDhw/H398fa2truU4nEAjMDKn6G591382ZMwdvb2+0Wq0usRYrVozE\nxESSkpKwtbXVfebZ/hx18/StckHRokVZtGiRXPICgcCMkarm+Iz58+czefJk+vTpQ2pqqm5/cnIy\ndnZ22Nrakpyc/NL+4sWL56hpVjNkBALB64FUT6t37NjBypUrAXTddzVr1iQ8PByAsLAwPDw8qFu3\nLgcPHkSj0RAbG4tGo8mxSQ1mNkNGIBC8Hki1Kk+7du2YMWMGAwYMICMjA39/f6pUqcKsWbMICgrC\nzc0Nb29vVCoVHh4e9O3bF41GQ2BgoF5tkRwFAkG+I9Vit9l1361fv/6VfWPHjmXs2LG5DVEkR4FA\nkP8oFQqUerKfvvflRiRHgUCQ7yhyMQhcIVYCFwgEhQ0l+l0QCvppcaFIjhoZZybo9cEwAjlnsZRs\nPlM27Qd/fSabNsg7i0XOxQ4sVPJp58NEN0mReiiPHGSbHJcuXZrjB8eMGSN5MAKBoHAg3AcFAoEg\nCxT//6fvmIIk2+T4Ys0wJSWF6OhoqlevztOnT7NcPEIgEAhyi1KRiz5HU1/s9siRI/j4+PDBBx9w\n//59WrZsycGDB/V9TCAQCLInNwvdmvpit0FBQWzYsAE7OzvKlClDSEgIX3zxRX7EliVyWm4C7Nq5\ng3KljPeM+S9arZYRw4bwddCXkmtLVSZdmr7Fnb3PZw4c+u4D/lk/nqNrxnB0zRg+7O8FgI21JWtm\n9yEyZDynNk6gS9O3CjTurJDbhlSu62kO9sBSYA6L3epNjhqNhjJlyuheV61aVdaAckJOy02Ay5cu\n4T99iuRP/s6fO0eHdq3Zvu0nSXVBujKp4lKKeWM66Hp5ihaxxK28Aw2GLMFz6FI8hy7l6w2ZLYaA\n4a1IepKG+4BFdJ7wAwsndaV8GcN+UMzVPhXku57mYA8sFc8GgevbChK9ydHR0ZEDBw6gUCh4/Pgx\ny5cvx9nZOT9iewU5LTdTUlIYPmwQn3/xldFa/2XF8m8Y6jeCHj17S64tRZnYWFvyQ2Bvpi3Zo9vn\n8bYLyU/SCA0aSsS6sXwxriNFrDK7qLs2e5sfQjMtYm/GP2J/xGV6tqqV73Fnh9w2pHJdT1O3B5YS\npUKhWw08283Uk+Mnn3zCrl27iIuLo02bNpw7d45PPvkkP2J7hZwsN41l7Oj38Bsxipq1cl46PS8s\nXLwU3379JdcFacpk6VQfVu+MIOryc4+Z4kWt+eufqwwI2IjXiOVUKFeCOe+3A8ClbAlu3XmkOzbm\nziPKlzWs5ijntaxUuTIdOnawzvihAAAgAElEQVQC5LEhlet6ylkm8NweuJprBQ4eDGPwkGGS6OYF\nc2hW6x3KU6pUKYKCgkhKSkKlUhWoMY9clpvfrliGhYUFQ4b6ceP6daO08htjy2RU94ZkqDWs232C\nio7P3eh2HzzP7oPnda+/WPcXm+b2Z8qiPSiVipctYRUKgy0A8ss+ddTwYdy6dZOdP/8ima5c5Jc9\ncFefbnz/3Sq6dm7P6XOXUCrzfy6KQqF/7nRBJ0e9pXLhwgW6d+9O69atadGiBf369cu1B/X9+/dp\n3rw5V65cMTpQkM9yc33wWk4cj8Czvjs9fDrx5MkTPOu7Excbq//DBYyxZTKoY13qveXC0TVj2PHl\nEGysLTm6ZgwDOrjT5J3KuuMUCgXpGZk+2zfjH+FU+nlN0al0cWJeqEnmR9z6MCUb0txiyvbAUqPI\n5VaQ6E2Os2fPZsKECYSHhxMeHo6fnx/+/v56hdPT0wkMDKRIkSKSBAryWW6GHQrneGQURyMi2bZz\nNzY2NhyNiMSpgPpWDcHYMmk6cjkegxbjOXQp3Sav5UlqOp5Dl1LU2pLPx3SgiJUFSqWCcX2b8NP+\nKAB+/vscfj71AShfxo62Dauz5/CFfI07J0zNhjS3mLI9sNSYg2+13mZ1amoqzZs3171u27Yt33zz\njV7h+fPn4+vry7fffmtchC8gp+WmuSJXmazeGYFreQeO/DAaC5WSv/65xtwf/gBgznf7WTy5KyfW\nj0OlVOL/zS9ci0kwibjB9GxIc4s52gPnFXMYBJ6tNWvs/5uUS5YswdXVlV69eqFSqdi1axfXr18n\nICAgW9Ft27Zx+/ZtPvjgAwYNGsRHH31ElSpVsj1ebmtWc114Qk7EwhNZU9C1lbwiV5nIZc1ae+xS\nrO3L5nhs6sM7/LtkjGTnNpRsa44DBw5EocjseA8PD2fTpk269xQKRY7JcevWrSgUCo4cOcK5c+eY\nNm0ay5cvf2m8pEAgKLyY9cITf/zxR55FQ0JCdP9/VnMUiVEgEDzDrJcse8b169dZv349KSkpaLVa\nNBoNt27deikBCgQCgSEoFQpUerqkTH4Q+MSJE7Gzs+PcuXO89dZbxMbGUu3/I/hzQ3BwcI79jQKB\noPBhDkN59NYc09PTGTduHBkZGbz99tv06dOHnj2lm6cqEAgKH+ZgsKW35mhjY0NaWhqVK1fmzJkz\nko5bFAgEhRNzmD6oNzl27dqV9957jxYtWrB+/XpGjBhBuXLl8iM2gUDwmvJaDAIfOHAg3bp1w9bW\nluDgYKKiovDy8sqP2AQCwetKbmqGpjqUJyeDrQsXLgiDLYFAkGfMoc+xUBhsmesslg9+ipJNW+5Z\nLHKS9DRDNu3iNpayaUffS5FNu2wJa1l00zLkmXlj1oPARc1QIBDIhQL9g7wLukpTKGqOAoHAtFAp\nFKj0JEd978uNSI4CgSDfUeRiVZ6CblbnagnglJQUzp8/j1arJSVFvn4TgUBQOHi2ZJm+rUBj1HfA\ni77V9+7dK3DfanOwOM0KY+P2rGTPx95V+ci7Kv5t3Khc8uUFXPu5OzG+aSXd61LFLPmweWU+7VCN\nWW2rUL9CiQKLPTukLu/vVi6jaYN3aNawDoN9e3D37nPr0ZhbN6n9RmXu379nbNiAdGWyY0sIPm08\ndVurBm9To0IJ7t2N57NZU2jv5U7bRrXYuHa1UbG+P3IYSxZmmsep1WomjhuNZ91aeNatxawZ0jtu\n6sMcxjmalW+1OVicZoWxcTsWt6JPHUeC/rrOR79dZteZu4z2qqh7v36FEnhWetkGYERDF67eTyHg\nl0ssOHCNDm+VpoK94bObzMWG9FTkPyxb8jW794YRFn4S1yrV+PzTjwDYvCEYnw6tuR0nje2FlGXS\nrc8Adu47ys59R/npl78pU7Ycsz4L4rfdO7l+9TI//xnBT7+EsXbVN/wbabj39oXz5/Dp2JbQ7Vt1\n+zZvWM/lSxc4FHGSv8P/4dDff7Pzhffzg9ei5mhKvtWmbnGaHcbGna7RsuZYDI/+P4TlekIKJYpY\noFIqcLKzpsNbpQk987JBe6WSNhy8lukP8jRDw7n4ZOq6GOYQKEXs2SF1eb/jXpejkWex+7/16O3Y\nGBwcHLgdF8svu0PZvO1nyWKXq0xWLQ3CoXQZfAcPZ98vofTwHYSFhQUl7EvSqVsvQrdu0i/yH1av\nXM6gocPx6dFLt0+tVpOSnExqaiqpqamkpadhbS3PUKDseC2mD5qSb7WpW5xmh7Fx309O59+453H4\nujtxMjYRC6WCkZ4ufBd+i6cZ6pc+czXhCV6uJQEobq2itnNxShQx/PmbOdmQWlpasufnndR505Uj\nhw/Sb8AQHJ2cWRPyI1WqVZcibECeMkm4f48fVi7G/+P5AMTFxODk/Hz1a0en8tyOjTFYd8HXi+nd\nt99L+/oPGoK9fUnerlqRt9xccHOrQodOXYz7Agai+P8g8Jw2k29Wm5JvtZzkhy2msVipFLzfuCJl\nba354dgthjUoz76L94l5lPrKsd8dvYmznTWftK/G0AYunIpNJENGuwhDkau8O3b24fz1OKbMmEWf\nHp3RaDRG6eUXW9b/QGvvTlSo5AqAVvty+Wi1WpQS3YvzP/uEUmXKcPF6LKcv3eDBgwSWLgqSRDu3\nKHO5FSS59q3OC926daN48eIAuLi4MG/evDzp5AcVKlQk4li47rXUVqHG4lDUkvFNKxH7OJUvDlzF\n1kpF9TLFcCxuTbs3SlPMSoWNpYoJzSqzMOw6liol34XfIk2dmRCH1C9PzKOnBfwtniN1eV+9cpk7\nd+LxbNQEgP6DhjJlwmgePniAgwmbaj1jT+hPBMx5/nDHqbwLd27H6V7fiY/D0UmaFtuu0B188dVC\nrKyssLKyot+AwezcvpUx4ydKop8bMgeB6z+mINGbHFu1apXlL/z+/ftz/FxqamZtJjg4OI+h5S+t\n27Zj+tRJXL50iarVqklqi2ksRSyUTGvlxqFrD3R9iw+eZDBx53ndMU1c7fFwKcGiv28A0K1WOW4k\nPOG3C/coV9yKOs7FX+mXLEikLu878bd5128QfxyKoFSp0vy0eQNvvl3DLBLjo4cPiL52Fff6nrp9\nrb07s3XTOlq260hKchK7d/zEx/MXSXK+d+q4s33rTzRt3pL09HR+2b2L+g0aSqKdW16LudUvJreM\njAz27t1LWlqaXuHz58/z5MkT/Pz8yMjIYOLEidSpU8e4aGXElG1fW1UrRamiltR1sXvpocqCA9dI\nTlNn+ZktJ+MY6VmBJq4lUWu1rA6/xYOU9PwKWS9Sl7dnYy8mTJ5O945tUFlY4OjozNoN0o9qkIMb\n169SppwjlpbP53X3GzKS6OtX8WntSXp6Gn0H+dGgcVNJzjd3/ldMmTiOBnVqoFKpaNaiFeMmTpFE\nO7colaDS025WFnC7Oltr1pzo0aMH27Zty/GYCxcucOrUKXr37s3169cZOXIkv/76KxYWr+Zjua1Z\nzRU5F55Y1quWbNpyk/hEviQvFp54mdiYGLp3aiu5NavPx99jWyrndWGT7sezc7af6VmzPiMiIkL3\nf61Wy6VLl3RN5pxwdXWlUqVKKBQKXF1dsbe35+7duzg5ORkXsUAgMHvMelWeZyxevFj3f4VCQcmS\nJfn888/1Cv/0009cvHiRjz76iPj4eJKSkoQ9q0AgAHI3yDs3g8DT09Px9/cnJiaGtLQ03n//fapW\nrcr06dNRKBRUq1aN2bNno1QqWbp0KX/++ScWFhb4+/tTu3btHLX1JseOHTvSr18/fYe9Qq9evZgx\nYwb9+vVDoVAwd+7cLJvUAoGg8KH4/z99x+gjNDQUe3t7FixYwIMHD+jevTtvvvkmEyZMoGHDhgQG\nBrJ//36cnZ05duwYP/74I3FxcYwdO5atW3OeFaQ3W4WEhOQpOVpZWfHVV18Z/DmBQPD6I9WqPO3b\nt8fb21v3WqVScebMGRo0aABAs2bNOHToEK6urnh5eaFQKHB2dkatVpOQkICDg0O22nqTo6OjI4MH\nD+add955aYqRWAxXIBDkFSW5aFbnQufZuNikpCTGjRvHhAkTmD9/vm74YbFixUhMTCQpKQl7e/uX\nPpeYmJhjctR7/jp16tCgQYN8n3spEAheX6RclScuLo7Bgwfj4+NDly5dUL4wBig5ORk7OztsbW1J\nTk5+af+zCSrZkW3Ncfv27XTv3l3UEAUCgeRI9UDm3r17+Pn5ERgYSKNGjQB4++23CQ8Pp2HDhoSF\nheHp6UnFihVZsGABw4cP5/bt22g0mhxrjZBDcly3bh3du3fXH51AIBAYSOYgcD0zZHLRrl6xYgWP\nHz9m2bJlLFu2DICZM2fy6aefEhQUhJubG97e3qhUKjw8POjbty8ajYbAwEC92uLxsUAgyHekqjkG\nBAQQEBDwyv7169e/sm/s2LGMHTs2tyFmnxwvXbpE69atX9mv1WpRKBR651YLBAJBdpj1IPBKlSrx\n7bff5mcsaDVaNDIsq2WuvtXmPMVPTioOlW/O+4PNw2XTrli6qGzacmFtKc8EZyUKlHrGMep7X26y\nTY6WlpaUL18+P2MRCASFBLOuOdatWzc/4xAIBIUIBbkYBJ4vkWRPtskxN09zBAKBIC+Yw3qOBb0S\nucFMnzqJN6pWwrO+O5713Rk8wFcybTmtWYW2fNpdGlTizvpButeTu9fm5OKenF7am5l93AEoUdSK\no192e2lL2jKMcV1qFljc2WEuVrjG8FoYbJka4UePsDZ4I0cjIjkaEcm6EMMd2bJCTmtWoS2fdhUn\nO+YNbqBbpMC7rgs9G7vReMpO6n24jeY1nejZ2JVHKWl4Tt6h29buv8jh8/Es23OmQOLODnOxwjUW\nfeZaualZyh5jgZ7dQFJTUzl1MpKvv1pA/bq16d+3FzejoyXRltOaVWjLo21jpeKHcc2Ztua5F03X\nBpXZcvAKKakZpKarWXfgEr7Nqrz0OTfH4kzrVYfhi/8iQ23Yd5GzTMB8rHCNRakAlZ6toAeZmFVy\njIuNpXmLVgR+PIdjJ05Rv0FD+vTqJskFltOaVWjLo730PS9W7z1P1I0E3T6X0sW4de/5HNqY+8mU\nL/WyadfH/T1YvucsN184Lj/jzglzssI1BinnVsuFWSXHyq6ubA/dTY0aNVEoFEyYOJlrV69w4/p1\no7XltGYV2tJrj/J+iwy1hnV/XHppv1KheOnHUgEvjZ11KVWMNnXK881uw5rTUsVdUJha3IpcbgWJ\nrMlx5cqV9O3blx49evDjjz8arRcV9S8bQl52M9RqtS8ZE+WVChUqEhcXq3stpTWr0JZee1DLatSr\nWoajX3Zjx8x22FipOPplN2LuJ+Pk8HywtZNDUWLuP68hdm9UmdDwGyQ9zZsPjZxlIiemFneh7nMM\nDw8nMjKSjRs3EhwczO3bt43WVCqVTJk4nuvXrgGwauVyataqTXkJzHdat23HsfCjXL6UWROR0ppV\naEuv3XR6KB4fbsNz8g66ffY7T9LUeE7eQeix6/RtWoWi1hZYWSgZ1LIaocduPP9cDScORMXmoCxv\n3AWFqcVtDjVH2RaeOHjwINWrV2f06NEkJSUxdepUozVr1KjJl18vplePrmjUapzLu7Bm3QYJopXX\nmlVo55/2nuM3qVHRgb/nd8XKQsnPx6IJ+fOy7v0qTnZE30kyubjlxtTiNocZMnmyZs0NAQEBxMbG\nsmLFCm7dusX777/Pr7/+mmW/xzO7xt2/7sNZBmtWc51bLciakn2/k01bzrnV5khMzC06tmstuTXr\n+MUbKFnWMcdjH9y5zaJx/U3XmjWv2Nvb4+bmhpWVFW5ublhbW5OQkECpUqXkOqVAIDATlOjv0yvo\np8Wynb9evXr8/fffaLVa4uPjefLkyUseDgKBoPBiDkN5ZKs5tmzZkoiICHr16oVWqyUwMNDkhzsI\nBIL8IXOxW31zq/MpmGyQdSVwKR7CCASC1w9zaFYLmwSBQJD/5KbZ/Lo2qwUCgSA7cjOOsaDHmIjk\nKBAI8h1zGOcokqNAIMh3zNpDRiAQCORC1BwFAoEgCxT//6fvmILEpJKjQqkwu6l+yakZsmnbWMo3\nLtTcyvlF5JziJ+fUxIRNfrJpy7VmrVYGq2QQNUeBQCDIEqVCgcrEDbZEchQIBPmOglzUHPMlkuwR\nyVEgEOQ75tDnWNAzdAzGHKxCAbZsCqG5Z11aNKpHh9ZNifznOACtvBrQuF5tWjSqR4tG9Viy8Cuj\n45bTrhbM0yo0P21fAZxKFiV0ljfhX3UjIqj7K6ZeuWVjyHoa1qtDQw93WjZrwokTx/OkkxVy3yeG\noFTkbitIzCo5moNVKMClixf4aOZ0Nu/YzZ9HTjBxqj9D+/chOTmZ69eu8tfRE/x5JHMbO2GS0bHL\nZVcL5mkVmt+2rwAfD6hHxKW7NJy0A59Pf2PxqMaUs7cx6HwXL1zAf8ZUdvz8C+HHI5k2Yyb9+vQ0\nOO7skPM+MRRFLv8VJGaVHE3dKvQZ1tbWLPxmJY6OTgDUca/HnfjbhB85RLFitvTp1ommDeowc9ok\nnjx5YlTcctrVgnlahRaE7atKqaREUavMz1pbkKHWvmTslRusra1ZtmIVTk6Z903deh7E375NWlqa\nQTpZIfd9YjCK50+ss9sKutPRrJKjqVuFPqNipcq0a98RyGySzpoxmfYdu5CamopXs+Z8H7yJvWFH\nibl5k09nzzQqbjntasE8rUILwvY1cH0EnTwqcnWVL5ELe/Lp5n+4+/ipQXFXqlyZDh07AZn3zfQp\nk+jUuStWVlYG6WSF3PeJoYiao8SYslVoViQnJzN8UD+uXb3Cwm9W0qFTF5avXktJBweKFCnChCnT\n2L1rpzFhy2pXKyemfC3zYvv6w4QWBO38F7eRm3CfsJVJ3WrjUbV0nuJPTk5mYL++XLlymWUrV+VJ\n47+Y2n1SqPsct23bxqBBgxg0aBB9+vShVq1aRne4m7JV6H+5dTOajq2bolSp2LFnHyXs7fl1z88c\nPvi37hgpbGXltKuVE1O+lobavpYqbk3jN8vx/d4LAFyJe8z+f2Pwejtnj5SsuBkdTatmTVCpVPy6\n9w/JVs83tfsks9VsyvVGGZNjjx49CA4OJjg4mBo1ahAQEICdnZ1RmqZsFfoiiYmJ+HRoQ6eu3Vm9\nNgQbm8yO+diYW8yeOZUnT56gVqtZvmQR3XoY15cnp12tnJjytTTU9vV+YioxCSn0aJT5cKZUcWu8\n3nYk4tJdg+JOTEzEu21LunbrzrqQjbr7RgpM7T4xh5qj7OMco6KiuHz5MrNnzzZay1ysQr9buYyb\n0TfYs2sHe3bt0O3f9vPv3Lh+jVZNGpChzsCraXMmzwgwKm457WrlxFyu5YvkZPvaa95egkY0Ynrv\nOmg0WhZs+5dD5+IN0l+xbCnRN24QunMHoTuf3zd7fttntDGdqd0nCoVC7wyYgvaQkc2a9Rljxoxh\n4MCBeHp6ZnvMM7vGPb/vp7wM1qxyIuZWv16IudUvExtzi07t20huzfrl99spU845x2Pvxscy2a/7\n62fNCvD48WOuXr2aY2IUCASFEDNYClzW5BgREUHjxo3lPIVAIDBDzGH6oKzJ8dq1awVSHRYIBKZN\noV+ybMSIEXLKCwQCM8UMWtXmNQhcIBC8Rij0bAZw6tQpBg3KXCDkxo0b9OvXj/79+zN79mw0Gg0A\nS5cupVevXvj6+vLvv//q1RTJUSAQ5DtSTh9ctWoVAQEBpKamAjBv3jwmTJjAhg0b0Gq17N+/nzNn\nznDs2DF+/PFHgoKC+Pjjj/XqiuQoEAjyHSkHgVesWJElS5boXp85c4YGDRoA0KxZMw4fPsyJEyfw\n8vJCoVDg7OyMWq0mISEhO8nMGPP87QQCgSCv6GtSG9C09vb2xsLi+eMTrVarG0BerFgxEhMTSUpK\nwtbWVnfMs/05IVYCFwgEBUBums15eySjVD6v8yUnJ2NnZ4etrS3Jyckv7S9evHjOOnk6u0AgEBiB\nvrUcczPUJzvefvttwsMz1+EMCwvDw8ODunXrcvDgQTQaDbGxsWg0GhwcHHLUKRQ1R0MXHTUEOaf4\nyTnOS84ykXtqolrG2OW0fX1j4i7ZtM9/1VkeYZkupZxDeaZNm8asWbMICgrCzc0Nb29vVCoVHh4e\n9O3bF41GQ2BgoF6dQpEcBQKBiSFxdnRxcWHLli0AuLq6sn79+leOGTt2LGPHjs21pkiOAoEg3yn0\n0wcFAoEgK8xh+qDZPZCR084TYNfOHZQrZdyivPmtvXzZUuq9UxOPOrXo3aMbd+7ckVRfrrjlvJan\nT0fRvm1LGjeoS9NG9Yn854Rk2sbGPaRpZfbOaMHv05uzamR9StlmesREzvVmz9Rmuq2bR3kAytpZ\ns+79hvwyrRm/TW9O9//vNxS57xNDkHAkj2yYVXKU084T4PKlS/hPnyKL6ZBc2v/8c4JFX3/FH2GH\nOH4yiqrVqvLJR7Mk05crbjmvZUpKCj6dvPlw4hQOH/uHaTMC8BsyUBJtY+OuWaEEI1tVocfXB2n3\n+V9cv5PMpE5v4la2GA9T0uj4RZhu23E8BoCpXd7i5I2HdJgfxuDl4XzapzZlilsbFLfc94mhKBSK\nXG0FiVklRzntPFNSUhg+bBCff/GV0Vr5qV23bj2izl6kRIkSPH36lNiYWBwcjFs1+hlyxi3ntdy/\n93fc3Krg3SHTAbJTl64Eb9hstC4YH/fpm49oMecPEp9mYG2hpJx9ER4kp1HP1QGNRsuP4xvz67Tm\njGtfTTdDRKVUULxIZg+YjZUKtUaDxsBykvM+yQtyDuWRCrNKjnLaeY4d/R5+I0ZRs1Zto7XyUxvA\n0tKS0J07qOZagYMHwxg8ZJgkunLGLee1vHzpImXLOfLBu8Np2qg+XTq0IyNDmhXbpYg7Q6OlXS1H\njn7SloZVHPgx/CYqpYKDF+4xeHk4fRYfovmbZRnaPNOTZv6uc7St5cixOW3Z59+CoD0XuZ9kuJe1\nXPdJXjHlJjWYWXKUy87z2xXLsLCwYMhQ6Zexl1P7Rbr6dONm3F1mzppN187tdSuR5BW545bTmjU9\nI53ff93DsOGj+PtIBO99MIYePp10CxMYg1Rx/x51G3f/3/j6l4sEv9+QzUejmb31NE/S1Dx+ksHq\nA1fxru0EwKLBdVmx/zINZu2lzdw/eb9NFd6pmDdXQqnvE6Mw8ewoW3JMT09n0qRJ+Pr60r9/f65c\nuWK0plx2nuuD13LieASe9d3p4dOJJ0+e4FnfnbjYWP0fLkBtgCuXL3P40EHd6yFD/Yi+cYMHDx4Y\npSt33HJaszo5OfPGm29Rv0FDADp39UGtVnPt6lWjtY2Nu1Lponi4PZ+ZseVoNOUditKjvgtvOj+f\nzqZQQIZaQ8liVtR3c2Dj4WgArt9N5u8L92hYNefZHf9Frvskr0i5Ko9cyJYc//rrLzIyMti0aROj\nR49m4cKFRmvKZecZdiic45FRHI2IZNvO3djY2HA0IhIn55wNgApaG+D27TgGD+zHvXv3ANi0IYQa\nNWoa7VYnd9xyWrO28+7AjevXdE+oD/4dhkKhoLKrq9HaxsZd1q4IS4fWpWSxzCfU3TxcuBD3mGqO\nxZnY8U2UCrC2VDK4aWV2/RPLg+Q04h4+oWOdzFpkyWJWNKziQOT1hwbFLdd9klfMoc9RtnGOrq6u\nqNVqNBoNSUlJL62akVfktPM0V5p4NWXqdH/at2mJysICJ2dnNv+0vaDD0ouc17KcoyMbf9zOh+NG\nk5ycjLW1NRs2b6VIkSJGaxsbd8TVBJb+fonNYxuRodFy59FTRq2K4G5iGnN61+T3GS2wUCrYfTKO\nTUcya4sjvo3g4141GeddHY1Wyzd7LxNxNefltv6Lqd0n5rASuGzWrHFxcXzwwQekpKTw4MEDVqxY\nQd26dbM8Vm5rVjnnEcuJnL+cchrymvPcapWMsZvj3OqYmFt08pbemnX15t2Uc8q5FRIfF8uIvp0K\nzJpVtmb1mjVr8PLy4rfffmPnzp1Mnz5dkg5xgUBg/mTWHE25x1HGZrWdnR2WlpYAlChRgoyMDNRq\ntVynEwgEZoQ5TB+ULTkOHToUf39/+vfvT3p6Oh9++CFFixaV63QCgcCMKNTJsVixYixatEgueYFA\nYMaIVXkEAoEgK3IzVOd1rTkKBAJBdpjDUB6RHAUCQf5jBtlRJEeBQJDviD5HgUAgyIJC/bRaIBAI\nssMMWtWFIznK+Qsk52rFaRnyLScl5ww/pcy3tZxT/OScmnghqIts2pU/+EkWXcXTB8hhGqIgFzVH\nGc5rCIUiOQoEAtMiNzYIBW2TIJKjQCDId0SzWiAQCLLCDAaBm5VNAoBWq2XEsCF8HfSlpLobQ9bT\nsF4dGnq407JZE06cOC6pvtQ2pFqtlvdGDGXx16+aXw3o25PJE8YapT1q+FAW/V9brVYzbfKH1K39\nNu+8XZ3vVq3Is/aLyG2zK8e9smH9OhrVd9dtNaq7YV/Mivj4eMnOYWzcfi2r8NdHbflzdlvWfNCY\n0sWtWf2uJ/tmtdFtFxf5sHZ0YwCavFGG3/xbsX9WG3ZPb4l75ZKSfZfsKNQrgcvB+XPn6NCuNdu3\nSdv5fPHCBfxnTGXHz78QfjySaTNm0q9PT8n0pbYhvXD+HF06tGXn9q2vvLfwqwUcOXwwi0/ljvPn\nz9G5/cva36/+lsuXLnLsn3/581A43yxZzPGIY3k+B8hvsyvXvdJ/4GCORERyJCKSsMPHKOfoyFcL\nl1CuXDlJ9I2Nu3ZFe95vW53O8w/Q4uO9XLuTxFSfGoxYeZQ2c/bRZs4+Jq87weOUNGZsiMRSpWDl\nyIZMCv6H1nP2sXD3eZb4NZDku+SIGRhXm1WzesXybxjqN4IKFSpKqmttbc2yFatwcspcir5uPQ/i\nb98mLS0NKysro/WzsvNsUO8dFi75Jk+dzqtWLGPIUD8qVKjw0v6/w/5k397f8BvxLg/z6A2yasUy\nhgzzw+UF7V07tzNs+PTvyVkAABEhSURBVEgsLCwoWbIkvXr3ZfPGEDzq5/2PSOoy+S9y3SsvEvTl\nfMqUKcvwke9Kpmls3P9GP6TRrF/JUGuxtlDiaF+E6HspuvctVQoWD6vPrM2niH3wBIA603aToc58\nSl+xTDEeJBvubGgoos9RYhYuXgpk+hJLSaXKlalUuTKQ2aSZPmUSnTp3lSQxQs52nnZ2hg+U+HLh\nEgD+2L9Xty8uNpbpkz9k6849/PDdt3mO9av/a+/f91z71q1blH8hfufy5Tl9+t88nyNTU9oy+S9y\n3SvPuHfvHksWBvH3EWm7X6SIO0OtpX0dZ74aXI+0dA1fhP6le6+/lyu3Hz3hl5OxLx1furg1ewPa\n4GBrxburwvP+BXKJOQwCN6tmtdwkJyczsF9frly5zLKVqyTTldOGFDKdHocPGcDcL77C8f+1XynR\n/Cd+rVZrdOxyl4nc/PDdt3Tq4oOrm1tBh5Ilv56MpcbEXXy56yybxnvpEs2oNtVYuPv8K8ffS0zF\nfdpuOs8/wMIhHriVtZU1vkLd55iWlsakSZPo06cPfn5+XL9+Xa5TScLN6GhaNWuCSqXi171/YG+f\nN1/grJDThhQg8sRxrl+7ysxpk/FqWJfvV69k29YtjHl/pCT6/43/dlyc0V4/cpeJ3Gz9cQsDBw8t\n6DBeoXKZYjSo+txRcOOha7iUKoZ9UStqVrDHQqng8MW7uveL21jQoc5zL5eo6IecvfWIt1xKyBuo\nGfQ5ypYct2zZQtGiRdmyZQsBAQHMmTNHrlMZTWJiIt5tW9K1W3fWhWzExsZGUn05bUgBGng24uzl\nGxwM/4eD4f/gN+JdevTsw9Ll0tR+O3XpSvDaH8jIyODhw4f89ONmo+OXu0zk5MGDB1y9chnPRo0L\nOpRXKFfChhUjG+Jgm9kl1LNhRc7HPOJBchqNqpfm4Pm7Lx2v1mj5eogH9atkJtQ3nOyo6licfwx0\nNzQUpSJ3W0EiW5/j5cuXadasGQBubm5cuXJFrlMZzYplS4m+cYPQnTsI3blDt3/Pb/sk8fU1d0vZ\nEaPe49rVKzSq7056WhrDRozCq1lzozTNuUyuXrmMo6OTziPJlAi/fI9Fe86zbVJzMjRa4h8+Ydiy\nwwC4lbXl5v3kl45PSVUzbPlh5vR9BwuVkrQMDe+vDifu4RNZ4zSHVXlks2bdvHkzp06d4rPPPuPU\nqVP069eP06dPZ9mnJLc1q0xfERBzq7PCQmW+Xdnmavsq69zq8C8lt2bdtnsvzs7lczw2NjaGHp3a\nvn7WrD179sTW1pbBgwdz4MABatSoYTad7QKBQCBbcoyKiqJevXoEBwfTpk2bV8bkCQSCwsuzVXly\n3Ao4Rtn6HCtVqsSiRYv4/vvvKV68OJ999plcpxIIBGaGOfQ5ypYcHRwcWLNmjVzyAoHAjDGHQeBm\nNUNGIBC8HojpgwKBQJAVZpAdRXIUCAT5TuYg75yz32s7CFwgEAiyQ6qKo0aj4aOPPuLChQtYWVnx\n6aefUqlSJQkiFAtPCASCgkCiudX79u0jLS2NzZs3M2nSJD7//HPJQjSJmqNarQYg/vZtWfTNdYZM\neoZ8ccvZZFGpCrorPe9oZJwho5Sx0BVP87Z+p17d1EfA879RqbgTH4++7HcnF6urnzhxgqZNmwJQ\np04dTp8+LUV4gIkkx7t3MyfDDxs8oIAjEQjMEznsU1/k7t27kjRXbW1tKVGiRK7/1kuUKIGtbfbL\npyUlJb30vkqlIiMjAwsL41ObSSTHmjVrEhISQpkyZcQUQ4HAhFCr1dy9e5eaNWtKomdvb8/vv/9O\nUlJSro63tbXNcflAW1tbkpOfL6ah0WgkSYxgIsmxSJEieHh4FHQYAoEgC6R6wPEMe3t7ydZLrVu3\nLgcOHKBjx46cPHmS6tWrS6ILMq7KIxAIBHLz7Gn1xYsX0Wq1zJ07lypVqkiiLZKjQCAQZIEYyiMQ\nCARZIJKjQCAQZIFIjgKBQJAFIjkKBAYguugLD2aTHLVaLRcuXODixYsFHYpBaDQa/vzzT/bt2ye5\ntlar5dKlS5w//6oPsRTaYWFhkutCZpnMnDmTyMhIWbR//PFHWWLXarV0796dxYsXy6J97tw52a7l\nxYsXOXv2rOTarzMmMc5RH1qtlvfff5+SJUuSkJBA+fLlCQwMlEx/7dq1DBkyRDK9Z2i1WkaPHo2j\noyMnTpwgLCyMTz75RDLtZ2Xy4MEDWrVqRZ8+fSTRhsxpWWPHjuXLL7+kZcuWkg2s1Wg0TJkyhdq1\na+Pu7o5Go0GplOY3WqvV4ufnh4eHB2lpaa/MnjAGjUZDYGAgRYsWpWTJkrrzSTF99Nm1tLOz4/Hj\nxzRq1Eiy+1Gj0TB69GjKly/PzZs3qVChAgEBAZJov+6YRc1xy5YtlCpVinnz5rF48WLOnj3Lxx9/\nLIl2cnIyGzZsICgoSBK9F1m7di0lS5Zk9uzZbN26lcePH5OYmCiJ9oYNGyhRogTz5s2jT58+3L9/\nXzL7W41GQ5kyZXBxcWHdunUcO3aMmzdvkpaWZrT23Llz0Wg0DBkyhEmTJjFx4kRmzZoliXZYWBjV\nq1dnzJgxHD9+nAULFhAYGChJU9jf3x9HR0fmzJnDvn37SEhIkGxe/Zo1ayhRogRffPEFgwcPJjU1\nlVu3bkmivXbtWuzs7AgICGDZsmX88ccfzJ49WxLt1x2zSI5VqlRBoVAQHx+PtbU169at4+zZs5Ik\ntKioKBwcHIiJicHf31+CaJ/j4uJC2bJlefr0KQ8fPuT+/fuS9Vm5uLhQokQJAPbu3cvvv/+Ov78/\n48ePN1pbqVRSunRpBg4cyMyZM1mwYAEDBgzg+vXrRmv7+vpy48YN+vX7X3t3GtPUtgVw/I+lQKUS\nBQWNcUAxgOIcg5E4odGoQYxGyUWM+kFjDMaB1LEMxhpHolGMJl5iUAExESmKsyjiPBsHnIWAWhBQ\nGmihQPs+EM4LeX08vT333YD79wm603V2etLVs88+e+0/CAkJISEhgR8/fqDT6RyO7e3tTUlJCTqd\njpCQEFauXInBYHB4lGE0GgkNDSU6Opr+/fvj5+dHbW0t0PRD4qgBAwZgNpt58+YN2dnZXLhwAY1G\nI8u59PX1Ra1WU1FRgUKhYNWqVbx8+ZLk5GSHY7d3bSY5qlQqnj17RmVlJS4uLuzbtw+z2fGNx319\nfYmMjGT79u3U1dURGxsrQ4+bjBgxgoiICNzc3ABoaGjAw8OD7Oxsjh8/7lDskSNHEh0dDcCkSZM4\nffo0GRkZNDY2UlFR4XDfLRYLnz9/prq6GicnJ7p27cqXL18cTgZ+fn4sWbKE3r17M3XqVDp37sze\nvXsxGo0On8/evXvj6+vLt2/fCAgIwNPTk0OHDlFeXk5VVdVfjuvh4cGUKVOk/xUKBTt37gSafkgc\n/cEbNmwYM2bMYOvWrRQWFpKZmUl6ejp1dXV8/frVodiBgYFYLBbS09PJyMjg+vXrxMTEyPLdae/a\nRHLs0qULERER5OXlkZ+fz+fPn3n8+DEfPnygrq7Oodg+Pj5MnjwZpVLJpk2baGhoYM2aNbL029PT\nkx49egCgUqkICgoiNzeXU6dOERwc7FBstVqNh0dTLZbJkydTX19PXl4eRqMRV1dXh/veqVMnvn//\nzu7du9HpdMTHx3PixAlMJpPDsSdOnMiyZctQKpVUVFRw69YtWW43uLu7M3fuXCwWCzdv3qSgoIAb\nN25QVVUlyz3T5iS4fv16unTpQlZWFuB42Tq1Ws3UqVOJiopi8ODB1NbWcu3aNaqrq3F3d3coto+P\nD0uXLqV79+58+fKFyMhIOnTowNu3b6mvrxez761oU8sHP336xNmzZ3n79i21tbWsXbuWAQMGyHqM\nyspK9u7dS3R0NN7e3rLFNRgMTJgwgaFDh7Jjxw769u0rW+wLFy5w9epVysvL2bRpE35+frLEffXq\nFT9+/GDMmDEAmEwmOnbsKEtsm83GqVOnOH/+PFarlY0bN8p2LouLi9Hr9Tx58gSlUsnq1avx9/eX\nJbbNZsNms5GZmUlZWRmLFy9GpVLJEru4uJikpCRUKhWFhYVotVrZziXAy5cvyc3NJS8vj23btsn+\n3Wlv2lRyhKahqdFoBJquzP4Ocs6gNjObzWi1WlasWCFrYoSmmnZGoxGFQoGPj4+sseHfn4dcs7PN\nqqurMZvN0rBdTlarlZqaGqxWq3RvVk5VVVXYbDbZqss0a560c3Z2lv1c1tXVUVRUhEqlolevXrLG\nbo/aXHJsyywWCy4uLv90NwRB+AkiOQqCINjRJiZkBEEQ/t9EchQEQbBDJEdBEAQ7RHJsB0pKSggK\nCiI8PJxZs2YxY8YMFi9ejMGBrW4zMzNZv349AEuWLKG0lW0y9+3bx8OHD38pvr1Ha/bv38/+/ftb\nfV9oaOgvLa37mZiCYI9Iju2Et7c3er2erKwscnJy8Pf3l1ZxOOrw4cOtPlby4MED2fc1FoR/Wpuo\nyiP8uuDgYGnteWhoKEOGDKGgoIC0tDTy8/NJSUnBarUyaNAg4uPjcXV1JSsri4MHD6JWq+nZs6f0\nwHdoaChHjx6lW7dubN68mUePHqFUKlm+fDkWi4UXL16g1WpJSkrCzc1NWi/t5uZGbGwsAwcOpKSk\nBI1Gg8lkYujQof+z/8ePH0ev12M2m1EqlSQmJtKvXz8AkpKSeP36Na6urmzevJmAgADKy8uJi4vD\nYDDg5ORETEyM9PC6IPwV4sqxHaqvr+fixYsMGzZMem3cuHFcvHiRyspKTp48yYkTJ9Dr9Xh5eZGc\nnExpaSm7d+8mNTWVjIyMFnsBNzt27Bgmk4nz589z5MgRDhw4wPTp0wkKCkKn0+Hv78+6devQaDSc\nPn2aLVu2sHr1agC2bNnC7Nmz0ev1jBgxotX+V1dXc+XKFY4dO8bZs2eZMGECqampUnufPn3Iyspi\n+fLl0tB/69atzJkzh8zMTA4ePEhcXNxP740sCPaIK8d2oqysjPDwcKDpYfMhQ4YQExMjtTdfrd27\nd4+ioiKp9mN9fT0DBw7kyZMnDB8+XFqpEhYWxt27d1sc48GDB8ybN48OHTrQrVs3cnJyWrTX1NTw\n4sULNmzYIL1mMpn4/v079+/fJzExEYCZM2e2WlNQrVaTmJhITk4OhYWF5OfnExgYKLXPnTsXgPHj\nx6PRaDAajdy+fZuPHz9KhWgbGhooLi7+hU9QEFoSybGdaL7n+N80F6NobGxk2rRpUnKqqamhsbGR\nO3futChCYK9Qg7Ozc4vlg0VFRVJhDWhasufi4tKiHwaDQVpi1xzfycmp1eWZX79+ZcGCBURFRTFu\n3Di6du1KQUGB1K5QKKS/bTYbzs7OWK1WUlJSpGOVlZXh5eX1t1RgF34PYlj9mwkODuby5ctSbcmE\nhARSUlIYOXIkT58+pbS0FKvVyrlz5/7jvaNGjeLcuXPYbDYqKiqIiorCYrGgUChobGykU6dO9O3b\nV0qOt27dYv78+QCMGTOG7OxsAC5dutRqNaXnz5/Tp08fFi1axODBg7ly5UqLCZ8zZ84ATXUs+/fv\nT8eOHRk9ejRpaWkAvH//nrCwMFGWS3CIuHL8zQQEBBAdHc3ChQuxWq0EBgaydOlSXF1d0Wq1LFq0\nCJVKZbcaTGRkJDqdjpkzZwIQGxuLWq1m7NixxMfHs2PHDnbt2kVCQgJ//vknSqWSPXv24OTkRFxc\nHBqNhoyMDIKCglotxRUSEkJ6ejrTp0/HZrMxatQo3r17J7UXFhYSHh6Ou7s727dvB0Cr1RIXF0dY\nWBgAO3fulG2LBOH3JNZWC4Ig2CGG1YIgCHaI5CgIgmCHSI6CIAh2iOQoCIJgh0iOgiAIdojkKAiC\nYIdIjoIgCHaI5CgIgmDHvwBKJO10PKhTTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ef7503ad68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at confusion matrix \n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part E - Gradient Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimenting on sgd\n",
      "Experimenting on momentum\n",
      "Experimenting on nesterov\n",
      "Experimenting on adagrad\n",
      "Experimenting on rmsprop\n",
      "Experimenting on adam\n",
      "\n",
      "sgd => mean accuracy: 0.8658666666666667, std: 0.017187075247276813\n",
      "momentum => mean accuracy: 0.7189333333333333, std: 0.16773863266668443\n",
      "nesterov => mean accuracy: 0.7629333333333334, std: 0.09716917663996588\n",
      "adagrad => mean accuracy: 0.7301333333333333, std: 0.2057232661179144\n",
      "rmsprop => mean accuracy: 0.8754666666666667, std: 0.0024729649321322067\n",
      "adam => mean accuracy: 0.8778666666666667, std: 0.0037142368739157706\n"
     ]
    }
   ],
   "source": [
    "n_feature = 2\n",
    "n_class = 2\n",
    "\n",
    "\n",
    "def make_network(n_hidden=100):\n",
    "    model = dict(\n",
    "        W1=np.random.randn(n_feature, n_hidden),\n",
    "        W2=np.random.randn(n_hidden, n_class)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "def forward(x, model):\n",
    "    # Input to hidden\n",
    "    h = x @ model['W1']\n",
    "    h[h < 0] = 0\n",
    "\n",
    "    # Hidden to output\n",
    "    prob = softmax(h @ model['W2'])\n",
    "\n",
    "    return h, prob\n",
    "\n",
    "\n",
    "def backward(model, xs, hs, errs):\n",
    "    dW2 = hs.T @ errs\n",
    "\n",
    "    dh = errs @ model['W2'].T\n",
    "    dh[hs < 0] = 0\n",
    "    dW1 = xs.T @ dh\n",
    "\n",
    "    return dict(W1=dW1, W2=dW2)\n",
    "\n",
    "\n",
    "def get_minibatch_grad(model, X_train, y_train):\n",
    "    xs, hs, errs = [], [], []\n",
    "\n",
    "    for x, cls_idx in zip(X_train, y_train):\n",
    "        h, y_pred = forward(x, model)\n",
    "\n",
    "        y_true = np.zeros(n_class)\n",
    "        y_true[int(cls_idx)] = 1.\n",
    "        err = y_true - y_pred\n",
    "\n",
    "        xs.append(x)\n",
    "        hs.append(h)\n",
    "        errs.append(err)\n",
    "\n",
    "    return backward(model, np.array(xs), np.array(hs), np.array(errs))\n",
    "\n",
    "\n",
    "def get_minibatch(X, y, minibatch_size):\n",
    "    minibatches = []\n",
    "\n",
    "    X, y = shuffle(X, y)\n",
    "\n",
    "    for i in range(0, X.shape[0], minibatch_size):\n",
    "        X_mini = X[i:i + minibatch_size]\n",
    "        y_mini = y[i:i + minibatch_size]\n",
    "\n",
    "        minibatches.append((X_mini, y_mini))\n",
    "\n",
    "    return minibatches\n",
    "\n",
    "\n",
    "def sgd(model, X_train, y_train, minibatch_size):\n",
    "    minibatches = get_minibatch(X_train, y_train, minibatch_size)\n",
    "\n",
    "    for iter in range(1, n_iter + 1):\n",
    "        idx = np.random.randint(0, len(minibatches))\n",
    "        X_mini, y_mini = minibatches[idx]\n",
    "\n",
    "        grad = get_minibatch_grad(model, X_mini, y_mini)\n",
    "\n",
    "        for layer in grad:\n",
    "            model[layer] += alpha * grad[layer]\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def momentum(model, X_train, y_train, minibatch_size):\n",
    "    velocity = {k: np.zeros_like(v) for k, v in model.items()}\n",
    "    gamma = .9\n",
    "\n",
    "    minibatches = get_minibatch(X_train, y_train, minibatch_size)\n",
    "\n",
    "    for iter in range(1, n_iter + 1):\n",
    "        idx = np.random.randint(0, len(minibatches))\n",
    "        X_mini, y_mini = minibatches[idx]\n",
    "\n",
    "        grad = get_minibatch_grad(model, X_mini, y_mini)\n",
    "\n",
    "        for layer in grad:\n",
    "            velocity[layer] = gamma * velocity[layer] + alpha * grad[layer]\n",
    "            model[layer] += velocity[layer]\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def nesterov(model, X_train, y_train, minibatch_size):\n",
    "    velocity = {k: np.zeros_like(v) for k, v in model.items()}\n",
    "    gamma = .9\n",
    "\n",
    "    minibatches = get_minibatch(X_train, y_train, minibatch_size)\n",
    "\n",
    "    for iter in range(1, n_iter + 1):\n",
    "        idx = np.random.randint(0, len(minibatches))\n",
    "        X_mini, y_mini = minibatches[idx]\n",
    "\n",
    "        model_ahead = {k: v + gamma * velocity[k] for k, v in model.items()}\n",
    "        grad = get_minibatch_grad(model, X_mini, y_mini)\n",
    "\n",
    "        for layer in grad:\n",
    "            velocity[layer] = gamma * velocity[layer] + alpha * grad[layer]\n",
    "            model[layer] += velocity[layer]\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def adagrad(model, X_train, y_train, minibatch_size):\n",
    "    cache = {k: np.zeros_like(v) for k, v in model.items()}\n",
    "\n",
    "    minibatches = get_minibatch(X_train, y_train, minibatch_size)\n",
    "\n",
    "    for iter in range(1, n_iter + 1):\n",
    "        idx = np.random.randint(0, len(minibatches))\n",
    "        X_mini, y_mini = minibatches[idx]\n",
    "\n",
    "        grad = get_minibatch_grad(model, X_mini, y_mini)\n",
    "\n",
    "        for k in grad:\n",
    "            cache[k] += grad[k]**2\n",
    "            model[k] += alpha * grad[k] / (np.sqrt(cache[k]) + eps)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def rmsprop(model, X_train, y_train, minibatch_size):\n",
    "    cache = {k: np.zeros_like(v) for k, v in model.items()}\n",
    "    gamma = .9\n",
    "\n",
    "    minibatches = get_minibatch(X_train, y_train, minibatch_size)\n",
    "\n",
    "    for iter in range(1, n_iter + 1):\n",
    "        idx = np.random.randint(0, len(minibatches))\n",
    "        X_mini, y_mini = minibatches[idx]\n",
    "\n",
    "        grad = get_minibatch_grad(model, X_mini, y_mini)\n",
    "\n",
    "        for k in grad:\n",
    "            cache[k] = gamma * cache[k] + (1 - gamma) * (grad[k]**2)\n",
    "            model[k] += alpha * grad[k] / (np.sqrt(cache[k]) + eps)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def adam(model, X_train, y_train, minibatch_size):\n",
    "    M = {k: np.zeros_like(v) for k, v in model.items()}\n",
    "    R = {k: np.zeros_like(v) for k, v in model.items()}\n",
    "    beta1 = .9\n",
    "    beta2 = .999\n",
    "\n",
    "    minibatches = get_minibatch(X_train, y_train, minibatch_size)\n",
    "\n",
    "    for iter in range(1, n_iter + 1):\n",
    "        t = iter\n",
    "        idx = np.random.randint(0, len(minibatches))\n",
    "        X_mini, y_mini = minibatches[idx]\n",
    "\n",
    "        grad = get_minibatch_grad(model, X_mini, y_mini)\n",
    "\n",
    "        for k in grad:\n",
    "            M[k] = beta1 * M[k] + (1. - beta1) * grad[k]\n",
    "            R[k] = beta2 * R[k] + (1. - beta2) * grad[k]**2\n",
    "\n",
    "            m_k_hat = M[k] / (1. - beta1**(t))\n",
    "            r_k_hat = R[k] / (1. - beta2**(t))\n",
    "\n",
    "            model[k] += alpha * m_k_hat / (np.sqrt(r_k_hat) + eps)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def shuffle(X, y):\n",
    "    Z = np.column_stack((X, y))\n",
    "    np.random.shuffle(Z)\n",
    "    return Z[:, :-1], Z[:, -1]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    X, y = make_moons(n_samples=5000, random_state=42, noise=0.1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    \n",
    "    n_iter = 100\n",
    "    eps = 1e-8  # Smoothing to avoid division by zero\n",
    "    alpha = 1e-2\n",
    "    minibatch_size = 100\n",
    "    n_experiment = 3\n",
    "\n",
    "    algos = dict(\n",
    "        sgd=sgd,\n",
    "        momentum=momentum,\n",
    "        nesterov=nesterov,\n",
    "        adagrad=adagrad,\n",
    "        rmsprop=rmsprop,\n",
    "        adam=adam\n",
    "    )\n",
    "\n",
    "    algo_accs = {k: np.zeros(n_experiment) for k in algos}\n",
    "\n",
    "    for algo_name, algo in algos.items():\n",
    "        print('Experimenting on {}'.format(algo_name))\n",
    "\n",
    "        for k in range(n_experiment):\n",
    "            # print('Experiment-{}'.format(k))\n",
    "\n",
    "            # Reset model\n",
    "            model = make_network()\n",
    "            model = algo(model, X_train, y_train, minibatch_size)\n",
    "\n",
    "            y_pred = np.zeros_like(y_test)\n",
    "\n",
    "            for i, x in enumerate(X_test):\n",
    "                _, prob = forward(x, model)\n",
    "                y = np.argmax(prob)\n",
    "                y_pred[i] = y\n",
    "\n",
    "            algo_accs[algo_name][k] = np.mean(y_pred == y_test)\n",
    "\n",
    "    print()\n",
    "\n",
    "    for k, v in algo_accs.items():\n",
    "        print('{} => mean accuracy: {}, std: {}'.format(k, v.mean(), v.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate for errors:\n",
    "* The most important errors\n",
    "* Get the difference between the probabilities of real value and the predicted ones in the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAERCAYAAAC0FCalAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDt5ERCrEwZuISIU4eBMRqdD/A1qVXOSMbLzWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ef1a2f4898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some error results \n",
    "\n",
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_val[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "\n",
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 6 errors \n",
    "most_important_errors = sorted_dela_errors[-6:]\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important errors are also the most intrigous.\n",
    "For those six case, the model is not ridiculous. Some of these errors can also be made by humans, especially for one the 3 that is very close to a 8. The 9 is also very misleading, it seems that it is a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict results\n",
    "# results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "# results = np.argmax(results,axis = 1)\n",
    "\n",
    "# results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part F- Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Relu  0.17021916596019082\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "# Set the CNN model \n",
    "# my CNN architechture is In:\n",
    "# -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation = \"softmax\"))\n",
    "  \n",
    "print (\"Using Relu \",time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "#submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datast = pd.read_csv('Churn_Modelling.csv')\n",
    "p = datast.iloc[:, 3:13].values\n",
    "t = datast.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "p[:, 1] = labelencoder_X_1.fit_transform(p[:, 1])\n",
    "\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "p[:, 2] = labelencoder_X_2.fit_transform(p[:, 2])\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "p = onehotencoder.fit_transform(p).toarray()\n",
    "\n",
    "p=p[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(p, t, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making ANN\n",
    "\n",
    "#importing keras lib and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#initializing ANN\n",
    "classifiero = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eklav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", kernel_initializer=\"uniform\", units=1)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# adding input layer and first hidden layer\n",
    "classifiero.add(Dense(units=6, activation='relu', kernel_initializer='uniform', input_dim=11))\n",
    "\n",
    "# adding second hidden layer ()\n",
    "classifiero.add(Dense(units=6, activation='relu', kernel_initializer='uniform'))\n",
    "\n",
    "# adding third hidden layer()\n",
    "#classifier.add(Dense(units=6, activation='relu', kernel_initializer='uniform'))\n",
    "\n",
    "# Adding output layer\n",
    "classifiero.add(Dense(output_dim=1, activation='sigmoid', kernel_initializer='uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifiero.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7500/7500 [==============================] - 3s 441us/step - loss: 0.4649 - acc: 0.7961\n",
      "Epoch 2/100\n",
      "7500/7500 [==============================] - 5s 612us/step - loss: 0.4249 - acc: 0.7963\n",
      "Epoch 3/100\n",
      "7500/7500 [==============================] - 2s 293us/step - loss: 0.4180 - acc: 0.8225\n",
      "Epoch 4/100\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 0.4172 - acc: 0.824 - 3s 373us/step - loss: 0.4161 - acc: 0.8253\n",
      "Epoch 5/100\n",
      "7500/7500 [==============================] - 3s 360us/step - loss: 0.4134 - acc: 0.8289\n",
      "Epoch 6/100\n",
      "7500/7500 [==============================] - 3s 336us/step - loss: 0.4125 - acc: 0.8312\n",
      "Epoch 7/100\n",
      "7500/7500 [==============================] - 3s 369us/step - loss: 0.4110 - acc: 0.8335\n",
      "Epoch 8/100\n",
      "7500/7500 [==============================] - 3s 411us/step - loss: 0.4104 - acc: 0.8329\n",
      "Epoch 9/100\n",
      "7500/7500 [==============================] - 3s 403us/step - loss: 0.4088 - acc: 0.8343\n",
      "Epoch 10/100\n",
      "7500/7500 [==============================] - 3s 353us/step - loss: 0.4086 - acc: 0.8333\n",
      "Epoch 11/100\n",
      "7500/7500 [==============================] - 2s 322us/step - loss: 0.4083 - acc: 0.8351\n",
      "Epoch 12/100\n",
      "7500/7500 [==============================] - 2s 314us/step - loss: 0.4073 - acc: 0.8345\n",
      "Epoch 13/100\n",
      "7500/7500 [==============================] - 2s 306us/step - loss: 0.4068 - acc: 0.8337\n",
      "Epoch 14/100\n",
      "7500/7500 [==============================] - 2s 294us/step - loss: 0.4064 - acc: 0.8353 0s - loss: 0.3985 \n",
      "Epoch 15/100\n",
      "7500/7500 [==============================] - 2s 303us/step - loss: 0.4058 - acc: 0.8337 1s - loss: \n",
      "Epoch 16/100\n",
      "7500/7500 [==============================] - 3s 339us/step - loss: 0.4049 - acc: 0.8317\n",
      "Epoch 17/100\n",
      "7500/7500 [==============================] - 3s 359us/step - loss: 0.4054 - acc: 0.8339\n",
      "Epoch 18/100\n",
      "7500/7500 [==============================] - 3s 339us/step - loss: 0.4049 - acc: 0.8315\n",
      "Epoch 19/100\n",
      "7500/7500 [==============================] - 3s 340us/step - loss: 0.4044 - acc: 0.8353 1s - loss:\n",
      "Epoch 20/100\n",
      "7500/7500 [==============================] - 3s 353us/step - loss: 0.4049 - acc: 0.8332\n",
      "Epoch 21/100\n",
      "7500/7500 [==============================] - 3s 350us/step - loss: 0.4040 - acc: 0.8335\n",
      "Epoch 22/100\n",
      "7500/7500 [==============================] - 3s 352us/step - loss: 0.4041 - acc: 0.8333 1s - loss: 0.4029  - ETA: \n",
      "Epoch 23/100\n",
      "7500/7500 [==============================] - 3s 404us/step - loss: 0.4041 - acc: 0.8339\n",
      "Epoch 24/100\n",
      "7500/7500 [==============================] - 4s 477us/step - loss: 0.4033 - acc: 0.8335\n",
      "Epoch 25/100\n",
      "7500/7500 [==============================] - 2s 314us/step - loss: 0.4039 - acc: 0.8351\n",
      "Epoch 26/100\n",
      "7500/7500 [==============================] - 3s 350us/step - loss: 0.4032 - acc: 0.8324\n",
      "Epoch 27/100\n",
      "7500/7500 [==============================] - 2s 330us/step - loss: 0.4035 - acc: 0.8329 1s - loss\n",
      "Epoch 28/100\n",
      "7500/7500 [==============================] - 2s 332us/step - loss: 0.4033 - acc: 0.8343\n",
      "Epoch 29/100\n",
      "7500/7500 [==============================] - 2s 313us/step - loss: 0.4028 - acc: 0.8335 1s - \n",
      "Epoch 30/100\n",
      "7500/7500 [==============================] - 2s 306us/step - loss: 0.4030 - acc: 0.8316\n",
      "Epoch 31/100\n",
      "7500/7500 [==============================] - 3s 374us/step - loss: 0.4021 - acc: 0.8365\n",
      "Epoch 32/100\n",
      "7500/7500 [==============================] - 3s 342us/step - loss: 0.4033 - acc: 0.8337 0s - loss: 0.4014 - acc: 0\n",
      "Epoch 33/100\n",
      "7500/7500 [==============================] - 3s 339us/step - loss: 0.4030 - acc: 0.8348\n",
      "Epoch 34/100\n",
      "7500/7500 [==============================] - 2s 322us/step - loss: 0.4027 - acc: 0.8339 0s - loss: 0.3992\n",
      "Epoch 35/100\n",
      "7500/7500 [==============================] - 2s 327us/step - loss: 0.4019 - acc: 0.8341\n",
      "Epoch 36/100\n",
      "7500/7500 [==============================] - 2s 322us/step - loss: 0.4026 - acc: 0.8348\n",
      "Epoch 37/100\n",
      "7500/7500 [==============================] - 3s 370us/step - loss: 0.4025 - acc: 0.8355\n",
      "Epoch 38/100\n",
      "7500/7500 [==============================] - 3s 352us/step - loss: 0.4029 - acc: 0.8340\n",
      "Epoch 39/100\n",
      "7500/7500 [==============================] - 3s 355us/step - loss: 0.4023 - acc: 0.8335\n",
      "Epoch 40/100\n",
      "7500/7500 [==============================] - 2s 331us/step - loss: 0.4024 - acc: 0.8343\n",
      "Epoch 41/100\n",
      "7500/7500 [==============================] - 2s 330us/step - loss: 0.4021 - acc: 0.8345\n",
      "Epoch 42/100\n",
      "7500/7500 [==============================] - 2s 316us/step - loss: 0.4018 - acc: 0.8339\n",
      "Epoch 43/100\n",
      "7500/7500 [==============================] - 3s 386us/step - loss: 0.4023 - acc: 0.8349\n",
      "Epoch 44/100\n",
      "7500/7500 [==============================] - 2s 331us/step - loss: 0.4027 - acc: 0.8345\n",
      "Epoch 45/100\n",
      "7500/7500 [==============================] - 3s 350us/step - loss: 0.4021 - acc: 0.8339\n",
      "Epoch 46/100\n",
      "7500/7500 [==============================] - 2s 333us/step - loss: 0.4019 - acc: 0.8344\n",
      "Epoch 47/100\n",
      "7500/7500 [==============================] - 4s 489us/step - loss: 0.4017 - acc: 0.8349\n",
      "Epoch 48/100\n",
      "7500/7500 [==============================] - 3s 466us/step - loss: 0.4013 - acc: 0.8355\n",
      "Epoch 49/100\n",
      "7500/7500 [==============================] - 2s 327us/step - loss: 0.4023 - acc: 0.8345\n",
      "Epoch 50/100\n",
      "7500/7500 [==============================] - 2s 330us/step - loss: 0.4014 - acc: 0.8349\n",
      "Epoch 51/100\n",
      "7500/7500 [==============================] - 3s 354us/step - loss: 0.4017 - acc: 0.8341\n",
      "Epoch 52/100\n",
      "7500/7500 [==============================] - 5s 605us/step - loss: 0.4013 - acc: 0.8329\n",
      "Epoch 53/100\n",
      "7500/7500 [==============================] - 3s 389us/step - loss: 0.4017 - acc: 0.8341\n",
      "Epoch 54/100\n",
      "7500/7500 [==============================] - 4s 467us/step - loss: 0.4013 - acc: 0.8353\n",
      "Epoch 55/100\n",
      "7500/7500 [==============================] - 3s 345us/step - loss: 0.4017 - acc: 0.8343\n",
      "Epoch 56/100\n",
      "7500/7500 [==============================] - 2s 325us/step - loss: 0.4019 - acc: 0.8343\n",
      "Epoch 57/100\n",
      "7500/7500 [==============================] - 2s 317us/step - loss: 0.4018 - acc: 0.8356\n",
      "Epoch 58/100\n",
      "7500/7500 [==============================] - 2s 330us/step - loss: 0.4022 - acc: 0.8323\n",
      "Epoch 59/100\n",
      "7500/7500 [==============================] - 2s 315us/step - loss: 0.4014 - acc: 0.8341\n",
      "Epoch 60/100\n",
      "7500/7500 [==============================] - 2s 331us/step - loss: 0.4019 - acc: 0.8335\n",
      "Epoch 61/100\n",
      "7500/7500 [==============================] - 2s 317us/step - loss: 0.4017 - acc: 0.8336\n",
      "Epoch 62/100\n",
      "7500/7500 [==============================] - 2s 320us/step - loss: 0.4021 - acc: 0.8336\n",
      "Epoch 63/100\n",
      "7500/7500 [==============================] - 2s 321us/step - loss: 0.4014 - acc: 0.8325\n",
      "Epoch 64/100\n",
      "7500/7500 [==============================] - 2s 319us/step - loss: 0.4011 - acc: 0.8348 0s - loss: 0.4003 - \n",
      "Epoch 65/100\n",
      "7500/7500 [==============================] - 2s 322us/step - loss: 0.4021 - acc: 0.8335\n",
      "Epoch 66/100\n",
      "7500/7500 [==============================] - 2s 315us/step - loss: 0.4015 - acc: 0.8353\n",
      "Epoch 67/100\n",
      "7500/7500 [==============================] - 2s 320us/step - loss: 0.4016 - acc: 0.8352\n",
      "Epoch 68/100\n",
      "7500/7500 [==============================] - 3s 334us/step - loss: 0.4015 - acc: 0.8355 0s - loss: 0\n",
      "Epoch 69/100\n",
      "7500/7500 [==============================] - 3s 418us/step - loss: 0.4013 - acc: 0.8336\n",
      "Epoch 70/100\n",
      "7500/7500 [==============================] - 2s 297us/step - loss: 0.4019 - acc: 0.8335\n",
      "Epoch 71/100\n",
      "7500/7500 [==============================] - 3s 345us/step - loss: 0.4018 - acc: 0.8344\n",
      "Epoch 72/100\n",
      "7500/7500 [==============================] - 2s 329us/step - loss: 0.4008 - acc: 0.8333 0s - loss: 0.39\n",
      "Epoch 73/100\n",
      "7500/7500 [==============================] - 2s 261us/step - loss: 0.4013 - acc: 0.8353\n",
      "Epoch 74/100\n",
      "7500/7500 [==============================] - 2s 295us/step - loss: 0.4015 - acc: 0.8333\n",
      "Epoch 75/100\n",
      "7500/7500 [==============================] - 2s 310us/step - loss: 0.4009 - acc: 0.8351\n",
      "Epoch 76/100\n",
      "7500/7500 [==============================] - 2s 307us/step - loss: 0.4017 - acc: 0.8347\n",
      "Epoch 77/100\n",
      "7500/7500 [==============================] - 2s 333us/step - loss: 0.4017 - acc: 0.8336\n",
      "Epoch 78/100\n",
      "7500/7500 [==============================] - 2s 328us/step - loss: 0.4016 - acc: 0.8343\n",
      "Epoch 79/100\n",
      "7500/7500 [==============================] - 3s 334us/step - loss: 0.4011 - acc: 0.8329\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 3s 344us/step - loss: 0.4012 - acc: 0.8373\n",
      "Epoch 81/100\n",
      "7500/7500 [==============================] - 3s 354us/step - loss: 0.4012 - acc: 0.8343\n",
      "Epoch 82/100\n",
      "7500/7500 [==============================] - 3s 382us/step - loss: 0.4012 - acc: 0.8351\n",
      "Epoch 83/100\n",
      "7500/7500 [==============================] - 3s 362us/step - loss: 0.4004 - acc: 0.8328 1s - loss: 0.4077 - acc: - ETA: 1s - loss\n",
      "Epoch 84/100\n",
      "7500/7500 [==============================] - 3s 363us/step - loss: 0.4011 - acc: 0.8364\n",
      "Epoch 85/100\n",
      "7500/7500 [==============================] - 3s 352us/step - loss: 0.4010 - acc: 0.8351\n",
      "Epoch 86/100\n",
      "7500/7500 [==============================] - 3s 372us/step - loss: 0.4008 - acc: 0.8353\n",
      "Epoch 87/100\n",
      "7500/7500 [==============================] - 3s 366us/step - loss: 0.4016 - acc: 0.8341\n",
      "Epoch 88/100\n",
      "7500/7500 [==============================] - 3s 368us/step - loss: 0.4015 - acc: 0.8351\n",
      "Epoch 89/100\n",
      "7500/7500 [==============================] - 3s 421us/step - loss: 0.4016 - acc: 0.8353\n",
      "Epoch 90/100\n",
      "7500/7500 [==============================] - 3s 372us/step - loss: 0.4006 - acc: 0.8343\n",
      "Epoch 91/100\n",
      "7500/7500 [==============================] - 3s 361us/step - loss: 0.4014 - acc: 0.8348 1s - loss:\n",
      "Epoch 92/100\n",
      "7500/7500 [==============================] - 3s 425us/step - loss: 0.4009 - acc: 0.8345 2s  - ETA: 0\n",
      "Epoch 93/100\n",
      "7500/7500 [==============================] - 3s 390us/step - loss: 0.4013 - acc: 0.8343\n",
      "Epoch 94/100\n",
      "7500/7500 [==============================] - 2s 333us/step - loss: 0.4013 - acc: 0.8341\n",
      "Epoch 95/100\n",
      "7500/7500 [==============================] - 3s 349us/step - loss: 0.4009 - acc: 0.8357\n",
      "Epoch 96/100\n",
      "7500/7500 [==============================] - 3s 366us/step - loss: 0.4011 - acc: 0.8339 \n",
      "Epoch 97/100\n",
      "7500/7500 [==============================] - 3s 351us/step - loss: 0.4012 - acc: 0.8343\n",
      "Epoch 98/100\n",
      "7500/7500 [==============================] - 3s 351us/step - loss: 0.4011 - acc: 0.8340 0s - loss: 0.4040 - acc:\n",
      "Epoch 99/100\n",
      "7500/7500 [==============================] - 3s 349us/step - loss: 0.4013 - acc: 0.8344\n",
      "Epoch 100/100\n",
      "7500/7500 [==============================] - 3s 347us/step - loss: 0.4004 - acc: 0.8351 2s - loss: 0.448 - ETA: 1s\n"
     ]
    }
   ],
   "source": [
    "classifiero.fit(X_train, y_train, batch_size=5, epochs=100)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifiero.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cmo = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1935,   56],\n",
       "       [ 331,  178]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part G - Network Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "\t<li>Change the network initialization. How does it effect the accuracy?</li>\n",
    "\t<li>How does it effect how quickly the network plateaus?</li>\n",
    "\t<li>Various forms of network initialization:</li>\n",
    "\t<li>Uniform</li>\n",
    "\t<li>Gaussian</li>\n",
    "\t<li>Xavier Glorot Initialization&nbsp;<a href=\"http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization\" target=\"_blank\">http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization</a>\n",
    "\t<ul>\n",
    "\t\t<li>Xavier Uniform</li>\n",
    "\t\t<li>Xavier Gaussian</li>\n",
    "\t</ul>\n",
    "\t</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eklav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", kernel_initializer=\"uniform\", units=1)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7500/7500 [==============================] - 3s 446us/step - loss: 0.5797 - acc: 0.7961\n",
      "Epoch 2/50\n",
      "7500/7500 [==============================] - 3s 385us/step - loss: 0.5121 - acc: 0.7963\n",
      "Epoch 3/50\n",
      "7500/7500 [==============================] - 3s 391us/step - loss: 0.5061 - acc: 0.7963\n",
      "Epoch 4/50\n",
      "7500/7500 [==============================] - 4s 581us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 5/50\n",
      "7500/7500 [==============================] - 4s 470us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 6/50\n",
      "7500/7500 [==============================] - 4s 470us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 7/50\n",
      "7500/7500 [==============================] - 4s 581us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 8/50\n",
      "7500/7500 [==============================] - 3s 375us/step - loss: 0.5056 - acc: 0.7963 1\n",
      "Epoch 9/50\n",
      "7500/7500 [==============================] - 4s 565us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 10/50\n",
      "7500/7500 [==============================] - 3s 427us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 11/50\n",
      "7500/7500 [==============================] - 5s 693us/step - loss: 0.5056 - acc: 0.7963 \n",
      "Epoch 12/50\n",
      "7500/7500 [==============================] - 6s 780us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 13/50\n",
      "7500/7500 [==============================] - 5s 696us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 14/50\n",
      "7500/7500 [==============================] - 3s 457us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 15/50\n",
      "7500/7500 [==============================] - 3s 431us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 16/50\n",
      "7500/7500 [==============================] - 3s 352us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 17/50\n",
      "7500/7500 [==============================] - 3s 362us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 18/50\n",
      "7500/7500 [==============================] - 3s 357us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 19/50\n",
      "7500/7500 [==============================] - 3s 366us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 20/50\n",
      "7500/7500 [==============================] - 3s 363us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 21/50\n",
      "7500/7500 [==============================] - 3s 363us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 22/50\n",
      "7500/7500 [==============================] - 3s 370us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 23/50\n",
      "7500/7500 [==============================] - 5s 624us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 24/50\n",
      "7500/7500 [==============================] - 3s 438us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 25/50\n",
      "7500/7500 [==============================] - 3s 427us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 26/50\n",
      "7500/7500 [==============================] - 3s 427us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 27/50\n",
      "7500/7500 [==============================] - 3s 423us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 28/50\n",
      "7500/7500 [==============================] - 3s 420us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 29/50\n",
      "7500/7500 [==============================] - 3s 458us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 30/50\n",
      "7500/7500 [==============================] - 4s 472us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 31/50\n",
      "7500/7500 [==============================] - 3s 387us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 32/50\n",
      "7500/7500 [==============================] - 3s 396us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 33/50\n",
      "7500/7500 [==============================] - 3s 459us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 34/50\n",
      "7500/7500 [==============================] - 4s 521us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 35/50\n",
      "7500/7500 [==============================] - 4s 558us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 36/50\n",
      "7500/7500 [==============================] - 4s 589us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 37/50\n",
      "7500/7500 [==============================] - 3s 447us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 38/50\n",
      "7500/7500 [==============================] - 3s 389us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 39/50\n",
      "7500/7500 [==============================] - 3s 390us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 40/50\n",
      "7500/7500 [==============================] - 3s 399us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 41/50\n",
      "7500/7500 [==============================] - 3s 397us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 42/50\n",
      "7500/7500 [==============================] - 3s 401us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 43/50\n",
      "7500/7500 [==============================] - 3s 441us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 44/50\n",
      "7500/7500 [==============================] - 4s 491us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 45/50\n",
      "7500/7500 [==============================] - 6s 739us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 46/50\n",
      "7500/7500 [==============================] - 4s 587us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 47/50\n",
      "7500/7500 [==============================] - 3s 399us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 48/50\n",
      "7500/7500 [==============================] - 4s 492us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 49/50\n",
      "7500/7500 [==============================] - 3s 433us/step - loss: 0.5056 - acc: 0.7963\n",
      "Epoch 50/50\n",
      "7500/7500 [==============================] - 3s 434us/step - loss: 0.5056 - acc: 0.7963\n"
     ]
    }
   ],
   "source": [
    "classifiero5 = Sequential()\n",
    "\n",
    "# adding input layer and first hidden layer\n",
    "classifiero5.add(Dense(units=6, activation='relu', kernel_initializer='uniform', input_dim=11))\n",
    "\n",
    "# adding second hidden layer ()\n",
    "classifiero5.add(Dense(units=6, activation='relu', kernel_initializer='uniform'))\n",
    "\n",
    "# adding third hidden layer()\n",
    "\n",
    "classifiero5.add(Dense(units=6, activation='relu', kernel_initializer='uniform'))\n",
    "\n",
    "# adding fourth hidden layer()\n",
    "\n",
    "classifiero5.add(Dense(units=6, activation='relu', kernel_initializer='uniform'))\n",
    "\n",
    "# Adding output layer\n",
    "classifiero5.add(Dense(output_dim=1, activation='sigmoid', kernel_initializer='uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifiero5.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fitting ANN to the training set\n",
    "classifiero5.fit(X_train, y_train, batch_size=5, epochs=50)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred5 = classifiero5.predict(X_test)\n",
    "y_pred5 = (y_pred5 > 0.5)\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cmo5 = confusion_matrix(y_test, y_pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1991,    0],\n",
       "       [ 509,    0]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
